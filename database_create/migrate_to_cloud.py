"""
å°†financial_asset_managementæ•°æ®è¿ç§»åˆ°äº‘ç«¯MySQLæ•°æ®åº“
ä½œè€…ï¼šAIåŠ©æ‰‹
æ—¥æœŸï¼š2025-12-20
"""
import pandas as pd
from sqlalchemy import create_engine, text, inspect
import warnings
import os
warnings.filterwarnings('ignore')

# äº‘ç«¯æ•°æ®åº“è¿æ¥ä¿¡æ¯
CLOUD_DB_CONFIG = {
    'host': 'mysql2.sqlpub.com',
    'port': 3307,
    'user': 'bobo11',
    'password': 'ls0OmCgVJIXHwawv',
    'database': 'wutongbei',
    'charset': 'utf8mb4'
}

def create_tables_from_structure(excel_structure_path, cloud_engine):
    """æ ¹æ®æ•°æ®è¡¨ç»“æ„.xlsxåˆ›å»ºè¡¨ç»“æ„"""
    print(f"\n{'='*60}")
    print("ç¬¬ä¸€æ­¥ï¼šåˆ›å»ºè¡¨ç»“æ„")
    print(f"{'='*60}\n")
    
    # è¯»å–è¡¨ç»“æ„æ–‡ä»¶
    try:
        df = pd.read_excel(excel_structure_path)
        print(f"âœ… æˆåŠŸè¯»å–è¡¨ç»“æ„æ–‡ä»¶ï¼Œå…± {len(df)} è¡Œå®šä¹‰")
    except Exception as e:
        print(f"âŒ è¯»å–è¡¨ç»“æ„æ–‡ä»¶å¤±è´¥: {e}")
        return False
    
    # åªå¤„ç†financial_asset_managementæ•°æ®åº“çš„è¡¨
    df_financial = df[df['åº“åè‹±æ–‡'] == 'financial_asset_management']
    
    if df_financial.empty:
        print("âŒ æœªæ‰¾åˆ°financial_asset_managementæ•°æ®åº“çš„è¡¨å®šä¹‰")
        return False
    
    unique_tables = df_financial['è¡¨è‹±æ–‡'].unique()
    print(f"ğŸ“Š éœ€è¦åˆ›å»º {len(unique_tables)} ä¸ªè¡¨: {', '.join(unique_tables)}\n")
    
    with cloud_engine.connect() as conn:
        for table_name in unique_tables:
            # æ£€æŸ¥è¡¨æ˜¯å¦å·²å­˜åœ¨
            inspector = inspect(cloud_engine)
            if table_name in inspector.get_table_names():
                print(f"  âš  è¡¨ {table_name} å·²å­˜åœ¨ï¼Œå…ˆåˆ é™¤...")
                try:
                    conn.execute(text(f"DROP TABLE IF EXISTS `{table_name}`"))
                    conn.commit()
                except Exception as e:
                    print(f"    åˆ é™¤è¡¨å¤±è´¥: {e}")
            
            # è·å–è¡¨ä¿¡æ¯
            table_info = df_financial[df_financial['è¡¨è‹±æ–‡'] == table_name].iloc[0]
            table_desc = table_info.get('è¡¨æè¿°', '') if 'è¡¨æè¿°' in table_info else ''
            
            # è·å–è¯¥è¡¨çš„æ‰€æœ‰å­—æ®µ
            table_fields = df_financial[df_financial['è¡¨è‹±æ–‡'] == table_name]
            
            # å…ˆæ‰¾å‡ºä¸»é”®å­—æ®µ
            primary_key_field = None
            for _, field_row in table_fields.iterrows():
                field_name = field_row['å­—æ®µè‹±æ–‡å']
                field_comment = str(field_row.get('ä¸­æ–‡æ³¨é‡Š', ''))
                if 'ä¸»é”®' in field_comment:
                    primary_key_field = field_name
                    break
            
            # æ„å»ºCREATE TABLEè¯­å¥
            create_table_sql = f"CREATE TABLE `{table_name}` (\n"
            
            columns_sql = []
            for _, field_row in table_fields.iterrows():
                field_name = field_row['å­—æ®µè‹±æ–‡å']
                field_chinese = field_row.get('å­—æ®µä¸­æ–‡å', '')
                field_comment = field_row.get('ä¸­æ–‡æ³¨é‡Š', '')
                
                # æ•°æ®ç±»å‹æ˜ å°„
                field_lower = field_name.lower()
                if field_name == primary_key_field:
                    col_def = f"  `{field_name}` INT AUTO_INCREMENT PRIMARY KEY"
                elif field_lower.startswith('is_') or field_lower.startswith('has_'):
                    col_def = f"  `{field_name}` TINYINT(1) DEFAULT 0"
                elif 'time' in field_lower or 'date' in field_lower:
                    col_def = f"  `{field_name}` DATETIME"
                elif 'amount' in field_lower or 'price' in field_lower or 'value' in field_lower or 'balance' in field_lower:
                    col_def = f"  `{field_name}` DECIMAL(15,2)"
                elif 'json' in str(field_comment).lower():
                    col_def = f"  `{field_name}` JSON"
                else:
                    col_def = f"  `{field_name}` VARCHAR(255)"
                
                # æ·»åŠ æ³¨é‡Š
                if field_chinese or field_comment:
                    comment = f"{field_chinese}"
                    if field_comment and pd.notna(field_comment):
                        comment += f": {field_comment}"
                    # è½¬ä¹‰å•å¼•å·
                    comment = comment.replace("'", "\\'")
                    col_def += f" COMMENT '{comment}'"
                
                columns_sql.append(col_def)
            
            create_table_sql += ',\n'.join(columns_sql)
            create_table_sql += f"\n) ENGINE=InnoDB DEFAULT CHARSET=utf8mb4 COLLATE=utf8mb4_unicode_ci"
            
            if table_desc and pd.notna(table_desc):
                table_desc = str(table_desc).replace("'", "\\'")
                create_table_sql += f" COMMENT='{table_desc}'"
            
            try:
                conn.execute(text(create_table_sql))
                conn.commit()
                print(f"  âœ… åˆ›å»ºè¡¨: {table_name}")
            except Exception as e:
                print(f"  âŒ åˆ›å»ºè¡¨ {table_name} å¤±è´¥: {e}")
                return False
    
    print(f"\nâœ… è¡¨ç»“æ„åˆ›å»ºå®Œæˆï¼\n")
    return True

def import_data_to_cloud(excel_data_path, cloud_engine):
    """å¯¼å…¥Excelæ•°æ®åˆ°äº‘ç«¯æ•°æ®åº“"""
    print(f"\n{'='*60}")
    print("ç¬¬äºŒæ­¥ï¼šå¯¼å…¥æ•°æ®")
    print(f"{'='*60}\n")
    
    # è¯»å–Excelæ–‡ä»¶çš„æ‰€æœ‰sheet
    try:
        excel_file = pd.ExcelFile(excel_data_path)
        print(f"ğŸ“‚ Excelæ–‡ä»¶: {os.path.basename(excel_data_path)}")
        print(f"ğŸ“Š Sheetæ•°é‡: {len(excel_file.sheet_names)}")
        print(f"ğŸ“‹ Sheetåˆ—è¡¨: {', '.join(excel_file.sheet_names)}\n")
    except Exception as e:
        print(f"âŒ è¯»å–Excelæ–‡ä»¶å¤±è´¥: {e}")
        return False
    
    # éå†æ¯ä¸ªsheet
    success_count = 0
    for sheet_name in excel_file.sheet_names:
        try:
            # è¯»å–sheetæ•°æ®
            df = pd.read_excel(excel_data_path, sheet_name=sheet_name)
            
            if df.empty:
                print(f"  âš  è¡¨ '{sheet_name}' ä¸ºç©ºï¼Œè·³è¿‡")
                continue
            
            print(f"  ğŸ“Š å¤„ç†è¡¨: {sheet_name} ({len(df)} è¡Œæ•°æ®)")
            
            # æ£€æŸ¥è¡¨æ˜¯å¦å­˜åœ¨
            inspector = inspect(cloud_engine)
            if sheet_name not in inspector.get_table_names():
                print(f"    âš  è¡¨ '{sheet_name}' ä¸å­˜åœ¨ï¼Œè·³è¿‡")
                continue
            
            # æ¸…ç†æ•°æ®ï¼šå¤„ç†NaNå€¼
            df = df.replace({pd.NA: None, 'nan': None, 'NaN': None})
            df = df.where(pd.notnull(df), None)
            
            # æ‰¹é‡æ’å…¥æ•°æ®
            batch_size = 500  # äº‘ç«¯æ•°æ®åº“ä½¿ç”¨è¾ƒå°çš„æ‰¹æ¬¡
            total_rows = len(df)
            inserted_rows = 0
            
            for i in range(0, total_rows, batch_size):
                batch_df = df.iloc[i:i+batch_size]
                
                try:
                    # ä½¿ç”¨pandasçš„to_sqlæ–¹æ³•æ‰¹é‡æ’å…¥
                    batch_df.to_sql(
                        name=sheet_name,
                        con=cloud_engine,
                        if_exists='append',
                        index=False,
                        method='multi',
                        chunksize=100
                    )
                    inserted_rows += len(batch_df)
                    if i + batch_size >= total_rows:
                        print(f"    âœ… è¿›åº¦: {inserted_rows}/{total_rows} è¡Œ")
                except Exception as e:
                    print(f"    âš  æ‰¹é‡æ’å…¥å¤±è´¥ (è¡Œ {i}-{i+len(batch_df)}): {e}")
                    # å°è¯•é€è¡Œæ’å…¥
                    for idx, row in batch_df.iterrows():
                        try:
                            row_df = pd.DataFrame([row.to_dict()])
                            row_df.to_sql(
                                name=sheet_name,
                                con=cloud_engine,
                                if_exists='append',
                                index=False
                            )
                            inserted_rows += 1
                        except Exception as row_error:
                            print(f"      è·³è¿‡é—®é¢˜è¡Œ {idx}: {row_error}")
            
            print(f"    âœ… æˆåŠŸå¯¼å…¥ {inserted_rows}/{total_rows} è¡Œæ•°æ®\n")
            success_count += 1
                
        except Exception as e:
            print(f"  âŒ å¤„ç†Sheet '{sheet_name}' æ—¶å‡ºé”™: {e}\n")
            continue
    
    print(f"âœ… æ•°æ®å¯¼å…¥å®Œæˆï¼æˆåŠŸå¯¼å…¥ {success_count}/{len(excel_file.sheet_names)} ä¸ªè¡¨\n")
    return success_count > 0

def main():
    """ä¸»å‡½æ•°"""
    print(f"\n{'#'*60}")
    print("# è´¢åŠ¡èµ„äº§ç®¡ç†æ•°æ®äº‘ç«¯è¿ç§»å·¥å…·")
    print("# Financial Asset Management Data Migration to Cloud")
    print(f"{'#'*60}\n")
    
    # è·å–è„šæœ¬æ‰€åœ¨ç›®å½•
    script_dir = os.path.dirname(os.path.abspath(__file__))
    
    # æ–‡ä»¶è·¯å¾„
    structure_file = os.path.join(script_dir, 'æ•°æ®è¡¨ç»“æ„.xlsx')
    data_file = os.path.join(script_dir, 'financial_asset_management.xlsx')
    
    # æ£€æŸ¥æ–‡ä»¶æ˜¯å¦å­˜åœ¨
    if not os.path.exists(structure_file):
        print(f"âŒ è¡¨ç»“æ„æ–‡ä»¶ä¸å­˜åœ¨: {structure_file}")
        return
    
    if not os.path.exists(data_file):
        print(f"âŒ æ•°æ®æ–‡ä»¶ä¸å­˜åœ¨: {data_file}")
        return
    
    # åˆ›å»ºäº‘ç«¯æ•°æ®åº“è¿æ¥
    connection_string = (
        f"mysql+pymysql://{CLOUD_DB_CONFIG['user']}:{CLOUD_DB_CONFIG['password']}"
        f"@{CLOUD_DB_CONFIG['host']}:{CLOUD_DB_CONFIG['port']}/{CLOUD_DB_CONFIG['database']}"
        f"?charset={CLOUD_DB_CONFIG['charset']}"
    )
    
    print(f"ğŸŒ è¿æ¥äº‘ç«¯æ•°æ®åº“...")
    print(f"   ä¸»æœº: {CLOUD_DB_CONFIG['host']}:{CLOUD_DB_CONFIG['port']}")
    print(f"   æ•°æ®åº“: {CLOUD_DB_CONFIG['database']}")
    print(f"   ç”¨æˆ·: {CLOUD_DB_CONFIG['user']}")
    
    try:
        cloud_engine = create_engine(connection_string, pool_pre_ping=True)
        # æµ‹è¯•è¿æ¥
        with cloud_engine.connect() as conn:
            result = conn.execute(text("SELECT DATABASE()"))
            db_name = result.fetchone()[0]
            print(f"âœ… è¿æ¥æˆåŠŸï¼å½“å‰æ•°æ®åº“: {db_name}\n")
    except Exception as e:
        print(f"âŒ è¿æ¥äº‘ç«¯æ•°æ®åº“å¤±è´¥: {e}")
        return
    
    # ç¬¬ä¸€æ­¥ï¼šåˆ›å»ºè¡¨ç»“æ„
    if not create_tables_from_structure(structure_file, cloud_engine):
        print("âŒ è¡¨ç»“æ„åˆ›å»ºå¤±è´¥ï¼Œåœæ­¢å¯¼å…¥")
        return
    
    # ç¬¬äºŒæ­¥ï¼šå¯¼å…¥æ•°æ®
    if not import_data_to_cloud(data_file, cloud_engine):
        print("âŒ æ•°æ®å¯¼å…¥å¤±è´¥")
        return
    
    print(f"\n{'#'*60}")
    print("# âœ… è¿ç§»å®Œæˆï¼")
    print("# ä½ çš„æ•°æ®å·²æˆåŠŸå¯¼å…¥åˆ°äº‘ç«¯æ•°æ®åº“")
    print(f"{'#'*60}\n")

if __name__ == '__main__':
    main()

