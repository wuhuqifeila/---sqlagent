"""
åŸºäº Streamlit çš„ SQL Agent Web ç•Œé¢
æä¾›èŠå¤©å¼äº¤äº’å’Œç»“æœå¯è§†åŒ–
"""
import streamlit as st
import sys
import os
import json
from io import BytesIO
from datetime import datetime
from typing import Any, Dict, List, Optional
from langchain_core.callbacks import BaseCallbackHandler
import time
import pandas as pd
from sqlalchemy import create_engine
import hashlib
import re
import asyncio

# Add missing import for HumanMessage
from langchain_core.messages import HumanMessage

# æ·»åŠ é¡¹ç›®æ ¹ç›®å½•åˆ° Python è·¯å¾„
sys.path.insert(0, os.path.dirname(os.path.dirname(os.path.abspath(__file__))))

from sqlagent import SQLAgent, Config
from sqlagent.agent import LIMIT_ALL, extract_limit_with_llm
from sqlagent.security import sanitize_sql_query, MAX_HARD_LIMIT
from sqlagent.code_sandbox import execute_analysis_code

# EChartsï¼ˆå¯é€‰ä¾èµ–ï¼Œæœªå®‰è£…æ—¶è‡ªåŠ¨é™çº§ä¸æ˜¾ç¤ºå›¾è¡¨ï¼‰
try:
    from streamlit_echarts import st_echarts  # type: ignore
    HAS_ECHARTS = True
except Exception:
    HAS_ECHARTS = False


class StreamlitStatusTraceHandler(BaseCallbackHandler):
    """æŠŠå·¥å…·è°ƒç”¨è¿‡ç¨‹å®æ—¶å†™åˆ° Streamlit çš„ st.statusï¼Œå±•ç¤ºå®Œæ•´æ‰§è¡Œæµç¨‹ã€‚"""

    def __init__(self, status_box):
        self.status_box = status_box
        self.step_no = 0
        self._current_tool: Optional[str] = None

    @staticmethod
    def _norm(v: Any) -> str:
        if v is None:
            return ""
        if isinstance(v, str):
            return v.strip()
        if isinstance(v, dict):
            # å¸¸è§ï¼š{"query": "..."} / {"tool_input": "..."}
            if "query" in v and isinstance(v["query"], str):
                return v["query"].strip()
            if "tool_input" in v and isinstance(v["tool_input"], str):
                return v["tool_input"].strip()
            return str(v)
        return str(v).strip()

    def on_tool_start(self, serialized: Dict[str, Any], input_str: Any = None, **kwargs) -> None:
        tool_name = (serialized or {}).get("name") or kwargs.get("name") or ""
        normalized_input = self._norm(input_str if input_str is not None else kwargs.get("input"))

        self.step_no += 1
        self._current_tool = tool_name
        
        # æ˜¾ç¤ºå·¥å…·è°ƒç”¨ä¿¡æ¯
        self.status_box.write(f"**{self.step_no}. è°ƒç”¨å·¥å…·ï¼š`{tool_name}`**")
        if normalized_input:
            if tool_name == "sql_db_query":
                self.status_box.write("è¾“å…¥ï¼ˆSQLï¼‰ï¼š")
                self.status_box.code(normalized_input, language="sql")
            else:
                self.status_box.write("è¾“å…¥ï¼š")
                self.status_box.code(normalized_input)

    def on_tool_end(self, output: Any, **kwargs) -> None:
        normalized_output = self._norm(output)
        if normalized_output:
            self.status_box.write("è¾“å‡ºï¼š")
            self.status_box.code(normalized_output)

    def on_tool_error(self, error: Exception, **kwargs) -> None:
        self.status_box.write(f"âŒ å·¥å…·æ‰§è¡Œå‡ºé”™ï¼š{error}")


class StreamlitAnswerStreamHandler(BaseCallbackHandler):
    """åªç”¨äºâ€œæœ€ç»ˆå›ç­”â€çš„ token æµå¼å±•ç¤ºã€‚"""

    def __init__(self, placeholder: "st.delta_generator.DeltaGenerator"):
        self.placeholder = placeholder
        self._buf: List[str] = []
        self._last_flush = 0.0

    def on_llm_new_token(self, token: str, **kwargs) -> None:
        self._buf.append(token)
        now = time.monotonic()
        # è½»å¾®èŠ‚æµï¼Œé¿å…æ¯ä¸ª token éƒ½è§¦å‘ UI é‡ç»˜
        if now - self._last_flush >= 0.05:
            self.placeholder.markdown("".join(self._buf))
            self._last_flush = now

    def flush(self) -> str:
        text = "".join(self._buf)
        self.placeholder.markdown(text)
        return text


@st.cache_resource
def get_sqlalchemy_engine(db_name: str):
    """å¤ç”¨ SQLAlchemy Engineï¼ˆé¿å…æ¯æ¬¡éƒ½æ–°å»ºè¿æ¥æ± ï¼‰ã€‚"""
    uri = Config.get_db_uri(db_name)
    engine_args = {
        "pool_pre_ping": True,
        "pool_size": 5,
        "max_overflow": 10,
        "pool_recycle": 3600,
        "connect_args": {"connect_timeout": 10},
    }
    return create_engine(uri, **engine_args)




def build_excel_bytes(df: pd.DataFrame) -> bytes:
    buf = BytesIO()
    with pd.ExcelWriter(buf, engine="openpyxl") as writer:
        df.to_excel(writer, index=False, sheet_name="result")
    return buf.getvalue()

def df_preview_text(df: pd.DataFrame, n: int = 20) -> str:
    """ç»™æ¨¡å‹ç”¨çš„æ ·ä¾‹æ–‡æœ¬ï¼šæœ€å¤š n è¡Œï¼Œé¿å…ä¸Šä¸‹æ–‡çˆ†ç‚¸ã€‚"""
    if df is None or df.empty:
        return "(ç©ºç»“æœ)"
    d = df.head(n).copy()
    # å…¨éƒ¨è½¬æˆå­—ç¬¦ä¸²ï¼Œé¿å… datetime/decimal ç­‰åœ¨ markdown é‡Œè¿‡é•¿
    for c in d.columns:
        d[c] = d[c].astype(str)
    try:
        return d.to_markdown(index=False)
    except Exception:
        # å…œåº•ï¼šCSV
        return d.to_csv(index=False)

def _chinese_num_to_int(s: str) -> Optional[int]:
    """æ”¯æŒ 1-99 çš„ä¸­æ–‡æ•°å­—ï¼ˆå«â€œå/äºŒå/äºŒåä¸€â€ï¼‰ã€‚"""
    s = s.strip()
    if not s:
        return None
    mapping = {"é›¶": 0, "ä¸€": 1, "äºŒ": 2, "ä¸¤": 2, "ä¸‰": 3, "å››": 4, "äº”": 5, "å…­": 6, "ä¸ƒ": 7, "å…«": 8, "ä¹": 9}
    if s == "å":
        return 10
    if "å" in s:
        left, _, right = s.partition("å")
        tens = 1 if left == "" else mapping.get(left)
        if tens is None:
            return None
        ones = 0 if right == "" else mapping.get(right)
        if ones is None:
            return None
        return tens * 10 + ones
    if len(s) == 1 and s in mapping:
        return mapping[s]
    return None


def _parse_user_limit(question: str) -> Optional[int]:
    """è§„åˆ™ä¼˜å…ˆï¼šè¿”å›ç”¨æˆ·æ˜ç¡®è¦æ±‚çš„è¡Œæ•°ï¼›æ— æ³•è¯†åˆ«åˆ™è¿”å› Noneã€‚"""
    q = (question or "").strip()
    if not q:
        return None

    # é˜¿æ‹‰ä¼¯æ•°å­—
    m = re.search(r"(?i)(?:top|å‰|æœ€å¤š|åªè¦|é™åˆ¶|è¿”å›|æ˜¾ç¤º|å–)\s*(\d{1,4})\s*(?:æ¡|è¡Œ)?", q)
    if m:
        return max(1, int(m.group(1)))

    # ä¸­æ–‡æ•°å­—
    m2 = re.search(r"(?:top|å‰|æœ€å¤š|åªè¦|é™åˆ¶|è¿”å›|æ˜¾ç¤º|å–)\s*([ä¸€äºŒä¸¤ä¸‰å››äº”å…­ä¸ƒå…«ä¹å]{1,3})\s*(?:æ¡|è¡Œ)?", q)
    if m2:
        n2 = _chinese_num_to_int(m2.group(1))
        if n2 is not None:
            return max(1, n2)

    # å…¨é‡å…³é”®è¯ï¼ˆæ”¾åœ¨æ•°å­—ä¹‹åï¼Œé¿å…â€œæ‰€æœ‰â€¦å‰5â€è¢«è¯¯åˆ¤ä¸ºå…¨é‡ï¼‰
    if re.search(r"(å…¨éƒ¨|æ‰€æœ‰|å…¨é‡|åˆ—å‡ºæ‰€æœ‰|æŸ¥è¯¢æ‰€æœ‰|å…¨éƒ¨æ•°æ®|æ‰€æœ‰æ•°æ®)", q):
        return LIMIT_ALL

    return None


def resolve_download_limit(question: str, llm) -> Optional[int]:
    """
    è§„åˆ™ä¼˜å…ˆ + LLM å…œåº•ï¼š
    - è¿”å› LIMIT_ALL è¡¨ç¤ºç”¨æˆ·è¦å…¨é‡
    - è¿”å› N è¡¨ç¤ºç”¨æˆ·è¦ N è¡Œ
    - è¿”å› None è¡¨ç¤ºæ— æ³•åˆ¤æ–­ï¼ˆæŒ‰åŸ SQL æ‰§è¡Œï¼‰
    """
    rule_limit = _parse_user_limit(question)
    if rule_limit is not None:
        return rule_limit

    try:
        llm_limit = extract_limit_with_llm(question, llm)
        if llm_limit:
            return llm_limit
    except Exception:
        pass

    return None

@st.cache_data(ttl=300, show_spinner=False)
def get_df_for_sql(db_name: str, sql: str) -> pd.DataFrame:
    """ä¸ºå†å²æ¶ˆæ¯é‡ç»˜/ä¸‹è½½é‡è·‘æä¾› DataFrameï¼ˆå¸¦ç¼“å­˜ï¼Œé¿å…é¢‘ç¹æ‰“åº“ï¼‰ã€‚"""
    engine = get_sqlalchemy_engine(db_name)
    return execute_sql_to_df(sql, engine)

def stable_key_for_sql(db_name: str, sql: str) -> str:
    raw = (db_name + "\n" + (sql or "")).encode("utf-8", errors="ignore")
    return hashlib.md5(raw).hexdigest()


# ç¼“å­˜å›¾è¡¨é…ç½®ï¼Œé¿å…å†å²æ¶ˆæ¯é‡å¤è°ƒç”¨ LLM
@st.cache_data(ttl=600, show_spinner=False)
def get_cached_echarts_option(cache_key: str, question: str, sql: str, df_info_json: str, _agent) -> Dict[str, Any]:
    """ç¼“å­˜ ECharts é…ç½®ç”Ÿæˆç»“æœï¼Œé¿å…å†å²æ¶ˆæ¯æ¯æ¬¡ rerun éƒ½é‡æ–°è°ƒç”¨ LLMã€‚"""
    import json
    df_info = json.loads(df_info_json) if df_info_json else {}
    return _agent.generate_echarts_option(question=question, sql=sql, df_info=df_info)

def build_df_info_for_viz(df: pd.DataFrame, max_rows: int = 20) -> Dict[str, Any]:
    """ç»™ LLM ç”¨çš„å¯è§†åŒ–ä¸Šä¸‹æ–‡ï¼šé¿å…å¡å…¨é‡ï¼Œæä¾›åˆ—ç±»å‹/åŸºæ•°/æ ·ä¾‹/ç®€å•ç»Ÿè®¡ã€‚"""
    if df is None or df.empty:
        return {"row_count": 0, "columns": [], "sample_rows": []}

    d = df.copy().head(max_rows)

    cols_info: List[Dict[str, Any]] = []
    for c in d.columns:
        s = d[c]
        # åŸºæœ¬ç±»å‹
        if pd.api.types.is_numeric_dtype(s):
            col_type = "number"
        elif pd.api.types.is_datetime64_any_dtype(s):
            col_type = "datetime"
        else:
            col_type = "string"

        nunique = int(s.astype(str).nunique(dropna=True))
        cols_info.append(
            {
                "name": str(c),
                "type": col_type,
                "nunique": nunique,
            }
        )

    # æ ·ä¾‹è¡Œï¼šè½¬æˆçº¯ Python ç±»å‹ï¼Œé¿å… datetime/decimal åºåˆ—åŒ–é—®é¢˜
    sample_rows = d.astype(str).to_dict(orient="records")

    # æ•°å€¼åˆ—ç®€å•ç»Ÿè®¡
    num_cols = [c for c in d.columns if pd.api.types.is_numeric_dtype(d[c])]
    numeric_summary: Dict[str, Any] = {}
    for c in num_cols[:5]:
        s = pd.to_numeric(d[c], errors="coerce")
        numeric_summary[str(c)] = {
            "min": float(s.min()) if s.notna().any() else None,
            "max": float(s.max()) if s.notna().any() else None,
            "mean": float(s.mean()) if s.notna().any() else None,
        }

    return {
        "row_count": int(len(df)),
        "columns": cols_info,
        "sample_rows": sample_rows,
        "numeric_summary": numeric_summary,
        "note": f"sample_rows ä»…ä¸ºå‰ {max_rows} è¡Œï¼Œç”¨äºé€‰å›¾ï¼›çœŸå®ç»“æœè¡Œæ•°è§ row_countã€‚",
    }

def execute_sql_to_df(sql: str, engine) -> pd.DataFrame:
    """
    ä½¿ç”¨ SQLAlchemy çš„ raw_connection è·å– DBAPI è¿æ¥ç›´æ¥æ‰§è¡Œ SQLï¼Œ
    è§„é¿æŸäº›é©±åŠ¨åœ¨åŒ…å« LIKE '%xx%' æ—¶æŠŠ % è¯¯å½“ä½œå ä½ç¬¦å¯¼è‡´çš„æ ¼å¼åŒ–é”™è¯¯ã€‚
    """
    q = (sql or "").strip().rstrip(";")
    if not q:
        return pd.DataFrame()

    conn = engine.raw_connection()
    try:
        cur = conn.cursor()
        cur.execute(q)  # ä¸ä¼ å‚æ•°ï¼Œç¡®ä¿ % ä½œä¸º SQL å­—é¢é‡ç”Ÿæ•ˆ
        rows = cur.fetchall()
        cols = [d[0] for d in (cur.description or [])]
        return pd.DataFrame(list(rows), columns=cols)
    finally:
        try:
            conn.close()
        except Exception:
            pass


def execute_scalar(sql: str, engine) -> Any:
    """æ‰§è¡Œè¿”å›å•ä¸ªå€¼çš„ SQLï¼ˆä¾‹å¦‚ COUNT(*)ï¼‰ã€‚"""
    q = (sql or "").strip().rstrip(";")
    if not q:
        return None
    conn = engine.raw_connection()
    try:
        cur = conn.cursor()
        cur.execute(q)
        row = cur.fetchone()
        return row[0] if row else None
    finally:
        try:
            conn.close()
        except Exception:
            pass


def strip_trailing_limit(sql: str) -> str:
    """
    å»é™¤æœ«å°¾ LIMIT å­å¥ï¼ˆä»…å¤„ç†æœ«å°¾çš„ LIMIT n / LIMIT offset,n / LIMIT n OFFSET offsetï¼‰ã€‚
    ç”¨äºè®¡ç®—â€œå…¨é‡è¡Œæ•°â€COUNT(*)ã€‚
    """
    s = (sql or "").strip().rstrip(";")
    # ç§»é™¤æœ«å°¾ LIMIT ...ï¼ˆå°½é‡ä¸å½±å“å­æŸ¥è¯¢å†… LIMITï¼‰
    s = re.sub(r"(?is)\s+limit\s+\d+\s*,\s*\d+\s*$", "", s)
    s = re.sub(r"(?is)\s+limit\s+\d+\s+offset\s+\d+\s*$", "", s)
    s = re.sub(r"(?is)\s+limit\s+\d+\s*$", "", s)
    return s.strip()


def auto_echarts_option(df: pd.DataFrame) -> Optional[Dict[str, Any]]:
    """æ ¹æ® df çš„åˆ—ç±»å‹è‡ªåŠ¨é€‰æ‹©ä¸€ä¸ªåˆé€‚çš„ ECharts optionï¼ˆç®€å•è§„åˆ™ç‰ˆï¼‰ã€‚"""
    if df is None or df.empty:
        return None

    # ç»˜å›¾æœ€å¤šä½¿ç”¨ 20 è¡Œï¼ˆä¸ç»“æœé™åˆ¶ä¸€è‡´ï¼‰
    d = df.copy().head(20)

    # å°è¯•è¯†åˆ«æ—¶é—´åˆ—
    datetime_cols: List[str] = []
    for c in d.columns:
        if pd.api.types.is_datetime64_any_dtype(d[c]):
            datetime_cols.append(c)
            continue
        if pd.api.types.is_object_dtype(d[c]):
            # å°è¯• parse
            parsed = pd.to_datetime(d[c], errors="coerce", utc=False)
            if parsed.notna().mean() > 0.8:
                d[c] = parsed
                datetime_cols.append(c)

    numeric_cols = [c for c in d.columns if pd.api.types.is_numeric_dtype(d[c])]
    cat_cols = [c for c in d.columns if c not in numeric_cols and c not in datetime_cols]

    # æ—¶é—´ + æ•°å€¼ => æŠ˜çº¿
    if datetime_cols and numeric_cols:
        x = datetime_cols[0]
        y = numeric_cols[0]
        dd = d[[x, y]].dropna().sort_values(x)
        return {
            "tooltip": {"trigger": "axis"},
            "xAxis": {"type": "category", "data": dd[x].dt.strftime("%Y-%m-%d %H:%M:%S").tolist()},
            "yAxis": {"type": "value"},
            "series": [{"type": "line", "data": dd[y].tolist(), "smooth": True}],
        }

    # åˆ†ç±» + æ•°å€¼ => æ¡å½¢
    if cat_cols and numeric_cols:
        x = cat_cols[0]
        y = numeric_cols[0]
        dd = d[[x, y]].dropna()
        # å–å‰ 20 ç±»
        dd = dd.head(20)
        return {
            "tooltip": {"trigger": "axis"},
            "xAxis": {"type": "category", "data": dd[x].astype(str).tolist(), "axisLabel": {"rotate": 30}},
            "yAxis": {"type": "value"},
            "series": [{"type": "bar", "data": dd[y].tolist()}],
        }

    # ä¸¤ä¸ªæ•°å€¼ => æ•£ç‚¹
    if len(numeric_cols) >= 2:
        x, y = numeric_cols[0], numeric_cols[1]
        dd = d[[x, y]].dropna().head(500)
        return {
            "tooltip": {"trigger": "item"},
            "xAxis": {"type": "value", "name": x},
            "yAxis": {"type": "value", "name": y},
            "series": [{"type": "scatter", "data": dd.values.tolist()}],
        }

    return None

# é¡µé¢é…ç½®
st.set_page_config(
    page_title="SQL Agent - æ™ºèƒ½æŸ¥è¯¢åŠ©æ‰‹",
    page_icon="ğŸ¤–",
    layout="wide"
)

# è‡ªå®šä¹‰æ ·å¼ï¼šå‡å°‘é—ªçƒï¼Œå¢å¼ºè§†è§‰åé¦ˆ
st.markdown("""
<style>
    /* è¿›åº¦æç¤ºåŠ¨ç”» */
    @keyframes pulse {
        0%, 100% { opacity: 1; }
        50% { opacity: 0.7; }
    }
    .stStatus { transition: all 0.3s ease; }
    
    /* æ•°æ®è¡¨æ ¼è¿‡æ¸¡ */
    .stDataFrame { 
        animation: fadeIn 0.3s ease-in-out;
    }
    @keyframes fadeIn {
        from { opacity: 0; transform: translateY(10px); }
        to { opacity: 1; transform: translateY(0); }
    }
    
    /* å›¾è¡¨å®¹å™¨ */
    iframe[title*="streamlit_echarts"] {
        animation: slideUp 0.4s ease-out;
    }
    @keyframes slideUp {
        from { opacity: 0; transform: translateY(20px); }
        to { opacity: 1; transform: translateY(0); }
    }
    
    /* èŠå¤©æ¶ˆæ¯ä¼˜åŒ– */
    .stChatMessage {
        transition: all 0.2s ease;
    }
    
    /* ä¸‹è½½æŒ‰é’®æ‚¬åœæ•ˆæœ */
    .stDownloadButton > button:hover {
        transform: translateY(-2px);
        box-shadow: 0 4px 12px rgba(0,0,0,0.15);
    }
    .stDownloadButton > button {
        transition: all 0.2s ease;
    }
    
    /* ä¾§è¾¹æ å†å²å¯¹è¯æŒ‰é’®æ ·å¼ */
    
    /* å…³é”®æŠ€å·§ï¼šåˆ©ç”¨ :has() é€‰æ‹©å™¨ï¼Œå½“æ°´å¹³å—å†…åŒ…å« primary æŒ‰é’®ï¼ˆé€‰ä¸­çŠ¶æ€ï¼‰æ—¶ï¼Œ
       ç»™æ•´ä¸ªæ°´å¹³å—ï¼ˆHorizontalBlockï¼‰æ·»åŠ èƒŒæ™¯è‰²ã€‚
    */
    [data-testid="stSidebar"] [data-testid="stHorizontalBlock"]:has(button[kind="primary"]) {
        background-color: rgba(26, 115, 232, 0.15);
        border-radius: 6px;
        padding-left: 4px;
        transition: all 0.2s ease-in-out; /* ä¸æ»‘è¿‡æ¸¡ */
    }

    /* æ‚¬åœæœªé€‰ä¸­è¡Œæ—¶ï¼šæ•´ä½“èƒŒæ™¯å˜ç° */
    [data-testid="stSidebar"] [data-testid="stHorizontalBlock"]:has(button[kind="secondary"]):hover {
        background-color: #f0f0f0;
        border-radius: 6px;
        padding-left: 4px;
        transition: all 0.2s ease-in-out; /* ä¸æ»‘è¿‡æ¸¡ */
    }
    
    /* é€‰ä¸­çŠ¶æ€ï¼ˆprimary æŒ‰é’®ï¼‰ï¼šèƒŒæ™¯é€æ˜ï¼Œæ–‡å­—è“è‰² */
    [data-testid="stSidebar"] .stButton button[kind="primary"] {
        background-color: transparent !important;
        color: #1a73e8 !important;
        border: none !important;
        box-shadow: none !important;
    }
    
    [data-testid="stSidebar"] .stButton button[kind="primary"]:hover {
        background-color: transparent !important;
        color: #1a73e8 !important;
    }
    
    /* æœªé€‰ä¸­çŠ¶æ€ï¼ˆsecondary æŒ‰é’®ï¼‰ */
    [data-testid="stSidebar"] .stButton button[kind="secondary"] {
        background-color: transparent !important;
        color: inherit !important;
        border: none !important; /* å»æ‰è¾¹æ¡† */
        transition: color 0.15s ease;
    }
    
    /* æœªé€‰ä¸­çŠ¶æ€æ‚¬åœæŒ‰é’®ï¼šä¸å•ç‹¬å˜è‰²ï¼Œç”±çˆ¶å®¹å™¨å˜è‰² */
    [data-testid="stSidebar"] .stButton button[kind="secondary"]:hover {
        background-color: transparent !important;
        color: inherit !important;
        border-color: transparent !important;
    }
    
    /* ä¸‰ç‚¹èœå•æŒ‰é’® */
    [data-testid="stSidebar"] .stPopover button {
        padding: 4px 8px !important;
        min-height: auto !important;
        background: transparent !important;
        border: none !important;
        opacity: 0; /* é»˜è®¤éšè— */
        transition: opacity 0.2s ease-in-out; /* ä¸æ»‘æ˜¾éš */
    }
    
    /* é€‰ä¸­è¡Œæ—¶ï¼šæ˜¾ç¤ºä¸‰ç‚¹èœå• */
    [data-testid="stSidebar"] [data-testid="stHorizontalBlock"]:has(button[kind="primary"]) .stPopover button {
        opacity: 1;
    }
    
    /* æ‚¬åœè¡Œæ—¶ï¼ˆæ— è®ºé€‰ä¸­ä¸å¦ï¼‰ï¼šæ˜¾ç¤ºä¸‰ç‚¹èœå• */
    [data-testid="stSidebar"] [data-testid="stHorizontalBlock"]:hover .stPopover button {
        opacity: 1;
    }
    
    [data-testid="stSidebar"] .stPopover button:hover {
        background: rgba(0,0,0,0.05) !important;
    }
</style>
""", unsafe_allow_html=True)

# ä½¿ç”¨ @st.cache_resource ç¼“å­˜ Agent å¯¹è±¡ï¼ˆè·¨ä¼šè¯å…±äº«ï¼Œåˆ·æ–°é¡µé¢ä¸é‡æ–°åˆå§‹åŒ–ï¼‰
@st.cache_resource
def get_sql_agent(db_name: str = None):
    """
    è·å–ç¼“å­˜çš„ SQL Agent å¯¹è±¡
    ä½¿ç”¨ @st.cache_resource ä½¿è¿æ¥åœ¨æ‰€æœ‰ç”¨æˆ·ä¼šè¯é—´å…±äº«
    åˆ·æ–°é¡µé¢æˆ–æ–°æ ‡ç­¾é¡µéƒ½ä¸ä¼šé‡æ–°åˆå§‹åŒ–
    """
    return SQLAgent(db_name=db_name)

# åˆå§‹åŒ– session state
if "conversations" not in st.session_state:
    st.session_state.conversations = []
if "current_conv_id" not in st.session_state:
    st.session_state.current_conv_id = None
if "db_name" not in st.session_state:
    st.session_state.db_name = Config.DB_NAME

# ç¡®ä¿è‡³å°‘æœ‰ä¸€ä¸ªå¯¹è¯
if not st.session_state.conversations:
    conv_id = f"conv-{int(time.time() * 1000)}"
    now_ts = time.time()
    st.session_state.conversations.append(
        {"id": conv_id, "messages": [], "created_at": now_ts, "updated_at": now_ts}
    )
    st.session_state.current_conv_id = conv_id

# ç»‘å®šå½“å‰å¯¹è¯çš„æ¶ˆæ¯åˆ—è¡¨
current_conv = next(
    (c for c in st.session_state.conversations if c["id"] == st.session_state.current_conv_id),
    None
)
if current_conv is None:
    conv_id = f"conv-{int(time.time() * 1000)}"
    now_ts = time.time()
    current_conv = {"id": conv_id, "messages": [], "created_at": now_ts, "updated_at": now_ts}
    st.session_state.conversations.append(current_conv)
    st.session_state.current_conv_id = conv_id

st.session_state.messages = current_conv["messages"]

# ç”¨äºæ›´é¡ºæ»‘çš„â€œè¿è¡Œä¸­ç¦ç”¨è¾“å…¥æ¡†â€ä½“éªŒï¼ˆä¸¤æ®µå¼ rerunï¼‰
if "pending_prompt" not in st.session_state:
    st.session_state.pending_prompt = None
if "is_running" not in st.session_state:
    st.session_state.is_running = False

# æ·»åŠ æ•°æ®åˆ†ææŠ¥å‘Šç›¸å…³çš„session state
if "analysis_reports" not in st.session_state:
    st.session_state.analysis_reports = {}

if "current_analysis_df" not in st.session_state:
    st.session_state.current_analysis_df = None

if "current_analysis_question" not in st.session_state:
    st.session_state.current_analysis_question = ""

# è·å–ç¼“å­˜çš„ Agentï¼ˆé¦–æ¬¡åŠ è½½ä¼šæ˜¾ç¤ºåŠ è½½æç¤ºï¼‰
try:
    with st.spinner("æ­£åœ¨è¿æ¥æ•°æ®åº“..."):
        agent = get_sql_agent(st.session_state.db_name)
except Exception as e:
    st.error(f"åˆå§‹åŒ– Agent å¤±è´¥: {e}")
    st.stop()

# ä¾§è¾¹æ é…ç½®
with st.sidebar:
    # æ–°å»ºå¯¹è¯ï¼ˆæ”¾åœ¨ä¾§è¾¹æ é¡¶éƒ¨ï¼‰
    if st.button("ğŸ†• æ–°å»ºå¯¹è¯", use_container_width=True, disabled=not st.session_state.messages):
        conv_id = f"conv-{int(time.time() * 1000)}"
        now_ts = time.time()
        st.session_state.conversations.append(
            {"id": conv_id, "messages": [], "created_at": now_ts, "updated_at": now_ts}
        )
        st.session_state.current_conv_id = conv_id
        st.rerun()

    # å†å²å¯¹è¯ï¼ˆGPT é£æ ¼åˆ—è¡¨ï¼‰
    st.subheader("ğŸ•˜ å†å²å¯¹è¯")

    def _conv_label(conv: Dict[str, Any]) -> str:
        for msg in conv.get("messages", []):
            if msg.get("role") == "user" and msg.get("content"):
                text = msg.get("content", "").strip()
                if text:
                    return text[:20] + ("..." if len(text) > 20 else "")
        return "æ–°å¯¹è¯"

    sorted_convs = sorted(
        st.session_state.conversations,
        key=lambda c: c.get("updated_at", c.get("created_at", 0)),
        reverse=True,
    )
    
    # é‡å‘½åçŠ¶æ€
    if "renaming_conv_id" not in st.session_state:
        st.session_state.renaming_conv_id = None
    
    if sorted_convs:
        for conv in sorted_convs:
            conv_id = conv.get("id")
            label = conv.get("title") or _conv_label(conv)
            is_selected = conv_id == st.session_state.current_conv_id
            
            # å¦‚æœæ­£åœ¨é‡å‘½åè¿™ä¸ªå¯¹è¯
            if st.session_state.renaming_conv_id == conv_id:
                col_input, col_ok = st.columns([0.8, 0.2])
                with col_input:
                    new_title = st.text_input(
                        "é‡å‘½å",
                        value=label,
                        key=f"rename-input-{conv_id}",
                        label_visibility="collapsed",
                    )
                with col_ok:
                    if st.button("âœ“", key=f"rename-ok-{conv_id}"):
                        conv["title"] = new_title
                        st.session_state.renaming_conv_id = None
                        st.rerun()
            else:
                # æ­£å¸¸æ˜¾ç¤ºï¼šå¯¹è¯æŒ‰é’® + ä¸‰ç‚¹èœå•
                col_btn, col_menu = st.columns([0.85, 0.15])
                with col_btn:
                    if st.button(
                        label,
                        key=f"conv-{conv_id}",
                        use_container_width=True,
                        type="primary" if is_selected else "secondary",
                    ):
                        st.session_state.current_conv_id = conv_id
                        st.rerun()
                
                # æ‚¬åœæˆ–é€‰ä¸­æ—¶æ˜¾ç¤ºä¸‰ç‚¹èœå•ï¼ˆç›®å‰ Streamlit åªèƒ½å®ç°é€‰ä¸­æ—¶ä¸€ç›´æ˜¾ç¤ºï¼Œæˆ–è€…ä¸€ç›´æ˜¾ç¤ºï¼‰
                # ä¸ºäº†å®ç°"æ‚¬åœæ˜¾ç¤º"æ•ˆæœï¼Œæˆ‘ä»¬éœ€è¦æ¥å—ä¸‰ç‚¹èœå•ä¸€ç›´å­˜åœ¨ï¼Œä½†æœªé€‰ä¸­æ—¶é¢œè‰²æ·¡åŒ–
                with col_menu:
                    # ä½¿ç”¨ popover å¹¶è‡ªå®šä¹‰ CSS è®©å…¶é»˜è®¤é€æ˜ï¼Œæ‚¬åœæ˜¾è‰²ï¼ˆè¾ƒéš¾å®Œç¾å®ç°ï¼‰
                    # ç°åœ¨çš„å¦¥åæ–¹æ¡ˆï¼šä¸€ç›´æ˜¾ç¤ºä¸‰ç‚¹èœå•ï¼Œä½†æœªé€‰ä¸­æ—¶æ·¡åŒ–
                    with st.popover("â‹®", use_container_width=True):
                        if st.button("âœï¸ é‡å‘½å", key=f"rename-{conv_id}", use_container_width=True):
                            st.session_state.renaming_conv_id = conv_id
                            st.rerun()
                        if st.button("ğŸ—‘ï¸ åˆ é™¤", key=f"delete-{conv_id}", use_container_width=True):
                            st.session_state.conversations = [
                                c for c in st.session_state.conversations if c["id"] != conv_id
                            ]
                            # å¦‚æœåˆ é™¤çš„æ˜¯å½“å‰å¯¹è¯ï¼Œåˆ‡æ¢åˆ°æœ€æ–°çš„
                            if st.session_state.current_conv_id == conv_id:
                                remaining = st.session_state.conversations
                                if remaining:
                                    st.session_state.current_conv_id = remaining[-1]["id"]
                                else:
                                    # æ²¡æœ‰å¯¹è¯äº†ï¼Œåˆ›å»ºä¸€ä¸ªæ–°çš„
                                    new_id = f"conv-{int(time.time() * 1000)}"
                                    now_ts = time.time()
                                    st.session_state.conversations.append(
                                        {"id": new_id, "messages": [], "created_at": now_ts, "updated_at": now_ts}
                                    )
                                    st.session_state.current_conv_id = new_id
                            st.rerun()
    else:
        st.caption("æš‚æ— å†å²å¯¹è¯")

    st.divider()

    # æ•°æ®åº“é€‰æ‹©ï¼ˆå›ºå®šåˆ—è¡¨ï¼Œæ˜ å°„åˆ°å®é™…æ•°æ®åº“ï¼‰
    st.title("âš™ï¸ é…ç½®")
    
    # æ˜¾ç¤ºåç§° -> å®é™…æ•°æ®åº“å çš„æ˜ å°„
    DB_DISPLAY_MAP = {
        "Financial Asset Management": "wutongbei",
        "Healthcare Analytics": "wutongbei",  # å‡é€‰é¡¹ï¼Œå®é™…ä¹Ÿè¿åˆ° wutongbei
    }
    display_names = list(DB_DISPLAY_MAP.keys())
    
    # åå‘æ˜ å°„ï¼šå®é™…æ•°æ®åº“å -> æ˜¾ç¤ºåç§°ï¼ˆç”¨äºæ˜¾ç¤ºå½“å‰é€‰ä¸­é¡¹ï¼‰
    def get_display_name(actual_db: str) -> str:
        for name, db in DB_DISPLAY_MAP.items():
            if db == actual_db:
                return name
        return actual_db
    
    try:
        current_display = get_display_name(st.session_state.db_name)
        current_index = display_names.index(current_display) if current_display in display_names else 0
        
        selected_display = st.selectbox(
            "é€‰æ‹©æ•°æ®åº“",
            display_names,
            index=current_index
        )
        
        # å°†æ˜¾ç¤ºåç§°æ˜ å°„ä¸ºå®é™…æ•°æ®åº“å
        actual_db = DB_DISPLAY_MAP.get(selected_display, "wutongbei")

        if actual_db != st.session_state.db_name:
            with st.spinner(f"åˆ‡æ¢åˆ°æ•°æ®åº“ {selected_display}..."):
                # æ¸…é™¤ç¼“å­˜ï¼Œé‡æ–°è·å–æ–°æ•°æ®åº“çš„ Agent
                get_sql_agent.clear()
                st.session_state.db_name = actual_db
                st.rerun()  # é‡æ–°è¿è¡Œä»¥ä½¿ç”¨æ–°çš„æ•°æ®åº“
    except Exception as e:
        st.error(f"æ•°æ®åº“é€‰æ‹©å¤±è´¥: {e}")

    st.divider()

    # å·²ç§»é™¤æ¸…ç©ºå¯¹è¯æŒ‰é’®ï¼Œæ”¹ä¸ºâ€œæ–°å»ºå¯¹è¯â€

# ä¸»ç•Œé¢
st.title("ğŸ¤– SQL Agent - æ™ºèƒ½ MySQL æŸ¥è¯¢åŠ©æ‰‹")
# æ˜¾ç¤ºå‹å¥½çš„æ•°æ®åº“åç§°
_db_friendly_names = {"wutongbei": "Financial Asset Management"}
_current_db_display = _db_friendly_names.get(st.session_state.db_name, st.session_state.db_name)
st.caption(f"å½“å‰æ•°æ®åº“: **{_current_db_display}**")

# æ˜¾ç¤ºå¯¹è¯å†å²ï¼ˆä½¿ç”¨ç¼“å­˜çš„æ•°æ®ï¼Œé¿å…é‡å¤æ¸²æŸ“ï¼‰
for msg_idx, message in enumerate(st.session_state.messages):
    with st.chat_message(message["role"]):
        # å¦‚æœæ˜¯åŠ©æ‰‹æ¶ˆæ¯ä¸”æœ‰å·¥å…·è°ƒç”¨è½¨è¿¹ï¼Œå…ˆæ˜¾ç¤ºè½¨è¿¹
        if message["role"] == "assistant" and message.get("trace"):
            with st.expander("ğŸ”§ æŸ¥çœ‹å·¥å…·è°ƒç”¨è¿‡ç¨‹", expanded=False):
                for step_idx, step in enumerate(message["trace"], 1):
                    tool_name = step.get("tool", "")
                    tool_input = step.get("input", "")
                    tool_output = step.get("output", "")
                    st.write(f"**{step_idx}. è°ƒç”¨å·¥å…·ï¼š`{tool_name}`**")
                    if tool_input:
                        if tool_name == "sql_db_query":
                            st.write("è¾“å…¥ï¼ˆSQLï¼‰ï¼š")
                            st.code(tool_input, language="sql")
                        else:
                            st.write("è¾“å…¥ï¼š")
                            st.code(tool_input)
                    if tool_output:
                        st.write("è¾“å‡ºï¼š")
                        st.code(tool_output[:2000] + ("..." if len(tool_output) > 2000 else ""))
        
        # å¦‚æœæ˜¯åŠ©æ‰‹æ¶ˆæ¯ä¸”æœ‰SQLï¼Œæ˜¾ç¤ºSQLï¼ˆä¼˜å…ˆå±•ç¤ºä¸‹è½½SQLï¼‰
        if message["role"] == "assistant" and ("download_sql" in message or "sql" in message):
            with st.expander("ğŸ“ æŸ¥çœ‹ç”Ÿæˆçš„ SQL è¯­å¥", expanded=False):
                st.code(message.get("download_sql") or message.get("sql", ""), language="sql")

        # å¦‚æœå†å²æ¶ˆæ¯é‡Œæœ‰ last_sqlï¼Œåˆ™é‡ç»˜"è¡¨æ ¼ + ä¸‹è½½ + å›¾è¡¨"
        if message["role"] == "assistant" and message.get("last_sql"):
            try:
                # è·å–ç¼“å­˜çš„ full_count
                full_count = message.get("full_count")

                # é¢„è§ˆç”¨ SQLï¼ˆå›ºå®šæœ€å¤š50è¡Œï¼‰ï¼šå…ˆå»æ‰åŸ LIMITï¼Œå†å¼ºåˆ¶åŠ  LIMIT 50
                preview_limit = 50
                sql_no_limit = strip_trailing_limit(message["last_sql"])
                preview_sql = sanitize_sql_query(sql_no_limit, default_limit=preview_limit, hard_limit=preview_limit)
                df_preview = get_df_for_sql(st.session_state.db_name, preview_sql)
                
                # æ˜¾ç¤ºå…¨é‡è¡Œæ•°
                if full_count is not None and full_count <= preview_limit:
                    st.markdown(f"**ğŸ“„ æŸ¥è¯¢ç»“æœï¼ˆå…± {full_count} è¡Œï¼Œå·²å…¨éƒ¨å±•ç¤ºï¼‰**")
                elif full_count is not None:
                    st.markdown(f"**ğŸ“„ æŸ¥è¯¢ç»“æœï¼ˆå‰ {len(df_preview)} è¡Œ / å…± {full_count} è¡Œï¼‰**")
                elif len(df_preview) <= preview_limit:
                    st.markdown(f"**ğŸ“„ æŸ¥è¯¢ç»“æœï¼ˆå…± {len(df_preview)} è¡Œï¼Œå·²å…¨éƒ¨å±•ç¤ºï¼‰**")
                else:
                    st.markdown(f"**ğŸ“„ æŸ¥è¯¢ç»“æœï¼ˆå‰ {len(df_preview)} è¡Œï¼‰**")
                st.dataframe(df_preview, use_container_width=True)

                # ä¸‹è½½ï¼šæŒ‰ç”¨æˆ·æ„å›¾å†³å®šè¡Œæ•°ï¼ˆè§„åˆ™ä¼˜å…ˆ + LLM å…œåº•ï¼‰
                question_text = message.get("question", "") or ""
                intent_limit = resolve_download_limit(question_text, agent.llm)
                if intent_limit is None:
                    download_sql = message["last_sql"]
                elif intent_limit >= LIMIT_ALL:
                    download_sql = strip_trailing_limit(message["last_sql"])
                else:
                    download_sql = sanitize_sql_query(
                        message["last_sql"], default_limit=intent_limit, hard_limit=intent_limit
                    )
                df_download = get_df_for_sql(st.session_state.db_name, download_sql)
                excel_bytes = build_excel_bytes(df_download)
                filename = f"query_result_{datetime.now().strftime('%Y%m%d_%H%M%S')}.xlsx"
                dl_key = (
                    f"download-{stable_key_for_sql(st.session_state.db_name, message['last_sql'])}"
                    f"-msg-{msg_idx}"
                )
                download_rows = len(df_download)
                st.download_button(
                    label=f"â¬‡ï¸ ä¸‹è½½ç»“æœï¼ˆExcelï¼Œå…± {download_rows} è¡Œï¼‰",
                    data=excel_bytes,
                    file_name=filename,
                    mime="application/vnd.openxmlformats-officedocument.spreadsheetml.sheet",
                    key=dl_key,
                )

                # æ–°å¢ï¼šè‡ªå®šä¹‰åˆ†æè¦æ±‚è¾“å…¥æ¡†
                custom_analysis_req = st.text_input(
                    "ğŸ“Š è‡ªå®šä¹‰åˆ†æè¦æ±‚ï¼ˆå¯é€‰ï¼‰:",
                    key=f"custom-analysis-req-{dl_key}",
                    placeholder="ä¾‹å¦‚ï¼šé‡ç‚¹å…³æ³¨é”€å”®é¢è¶‹åŠ¿ã€æŒ‰åœ°åŒºåˆ†ç»„ç»Ÿè®¡ã€ç”Ÿæˆç›¸å…³æ€§çƒ­åŠ›å›¾ç­‰"
                )

                # æ–°å¢ï¼šç”Ÿæˆæ•°æ®åˆ†ææŠ¥å‘ŠæŒ‰é’®
                report_key = f"report-{dl_key}"
                if st.button("ğŸ“Š ç”Ÿæˆæ•°æ®åˆ†ææŠ¥å‘Š", key=f"generate-report-{dl_key}"):
                    try:
                        with st.spinner("æ­£åœ¨ç”Ÿæˆæ•°æ®åˆ†ææŠ¥å‘Š..."):
                            # ä¿å­˜å½“å‰åˆ†ææ‰€éœ€çš„æ•°æ®
                            st.session_state.current_analysis_df = df_download.copy()
                            st.session_state.current_analysis_question = message.get("question", "")
                            
                            # ç”ŸæˆExcelæ–‡ä»¶ç”¨äºæ²™ç®±æ‰§è¡Œ
                            excel_filename = f"temp_data_{datetime.now().strftime('%Y%m%d_%H%M%S')}.xlsx"
                            excel_path = f"/tmp/{excel_filename}"
                            df_download.to_excel(excel_path, index=False)
                            
                            # ç”ŸæˆPDFæŠ¥å‘Šæ–‡ä»¶è·¯å¾„
                            report_filename = f"analysis_report_{datetime.now().strftime('%Y%m%d_%H%M%S')}.pdf"
                            report_path = f"/tmp/{report_filename}"
                            
                            # æ„å»ºåˆ†ææç¤ºè¯
                            base_prompt = f"""
ä½ æ˜¯ä¸€åä¸“ä¸šçš„æ•°æ®ç§‘å­¦å®¶ã€‚è¯·åŸºäºç”¨æˆ·çš„é—®é¢˜å’Œæä¾›çš„DataFrameï¼ˆå˜é‡å: dfï¼‰ç”Ÿæˆå®Œæ•´çš„Pythonæ•°æ®åˆ†æä»£ç ã€‚

ç”¨æˆ·é—®é¢˜: {st.session_state.current_analysis_question}
"""
                            
                            if custom_analysis_req.strip():
                                base_prompt += f"\nç”¨æˆ·è‡ªå®šä¹‰åˆ†æè¦æ±‚: {custom_analysis_req.strip()}\n"
                            
                            analysis_prompt = base_prompt + f"""
è¦æ±‚ï¼š
1. è¿›è¡Œå…¨é¢çš„æ•°æ®åˆ†æï¼ŒåŒ…æ‹¬åŸºæœ¬ç»Ÿè®¡ã€ç›¸å…³æ€§åˆ†æã€åˆ†å¸ƒåˆ†æç­‰
2. ç”Ÿæˆé«˜è´¨é‡çš„å¯è§†åŒ–å›¾è¡¨ï¼ˆä½¿ç”¨matplotlib/seabornï¼‰ï¼Œ**æ‰€æœ‰å›¾è¡¨æ ‡é¢˜ã€æ ‡ç­¾ã€å›¾ä¾‹å¿…é¡»ä½¿ç”¨è‹±æ–‡**
3. å°†æ‰€æœ‰åˆ†æç»“æœæ•´åˆåˆ°ä¸€ä¸ªPDFæŠ¥å‘Šä¸­ï¼Œ**åŒ…å«è¯¦ç»†çš„ä¸­æ–‡æ–‡å­—æè¿°å’Œè§£é‡Š**
4. PDFæŠ¥å‘Šå¿…é¡»ä¿å­˜åˆ°è·¯å¾„: {report_path}
5. **ä¸­æ–‡æ–‡å­—æè¿°å†…å®¹åº”åŒ…æ‹¬**ï¼š
   - æ•°æ®æ¦‚è§ˆï¼ˆå½¢çŠ¶ã€åˆ—ä¿¡æ¯ã€æ•°æ®ç±»å‹ï¼‰
   - ç¼ºå¤±å€¼åˆ†æ
   - åŸºæœ¬ç»Ÿè®¡æ‘˜è¦
   - æ•°å€¼åˆ—çš„åˆ†å¸ƒç‰¹å¾åˆ†æ
   - åˆ†ç±»åˆ—çš„é¢‘æ¬¡åˆ†æ  
   - ç›¸å…³æ€§åˆ†æï¼ˆå¦‚æœé€‚ç”¨ï¼‰
   - å…³é”®å‘ç°å’Œæ´å¯Ÿæ€»ç»“
6. ä¸è¦ä½¿ç”¨plt.show()ï¼Œç›´æ¥ä¿å­˜å›¾è¡¨åˆ°PDF
7. ç¡®ä¿ä»£ç å®Œæ•´å¯è¿è¡Œï¼ŒåŒ…å«æ‰€æœ‰å¿…è¦çš„importè¯­å¥
8. **é‡è¦ï¼šå¤„ç†ä¸­æ–‡æ ‡ç­¾æ—¶ä½¿ç”¨æä¾›çš„è½¬æ¢å‡½æ•°**ï¼š
   ```python
   # å¦‚æœæ‚¨çš„æ•°æ®åŒ…å«ä¸­æ–‡åˆ†ç±»æ ‡ç­¾ï¼Œä½¿ç”¨ä»¥ä¸‹å‡½æ•°è½¬æ¢ä¸ºè‹±æ–‡
   # x_labels = safe_translate_labels(original_labels)
   # ax.set_xticklabels(x_labels)
   
   # æˆ–è€…åœ¨åˆ›å»ºå›¾è¡¨æ—¶ç›´æ¥è½¬æ¢
   # categories = [translate_chinese_to_english(cat) for cat in original_categories]
   ```
9. **å¿…é¡»åŒ…å«matplotlibè‹±æ–‡é…ç½®**ï¼š
   ```python
   import matplotlib.pyplot as plt
   import matplotlib
   matplotlib.rcParams['font.sans-serif'] = ['DejaVu Sans', 'Arial', 'Helvetica']
   matplotlib.rcParams['axes.unicode_minus'] = False
   ```
10. **å¿…é¡»åŒ…å«reportlabä¸­æ–‡å­—ä½“é…ç½®**ï¼š
    ```python
    from reportlab.pdfbase import pdfmetrics
    from reportlab.pdfbase.ttfonts import TTFont
    import os
    
    # æ³¨å†Œä¸­æ–‡å­—ä½“ç”¨äºPDFæ–‡å­—æè¿°
    font_name = 'Helvetica'
    try:
        font_paths_to_try = [
            '/usr/share/fonts/truetype/wqy/wqy-zenhei.ttc',
            '/usr/share/fonts/truetype/wqy/wqy-microhei.ttc',
            '/usr/share/fonts/truetype/dejavu/DejaVuSans.ttf'
        ]
        
        for font_path in font_paths_to_try:
            try:
                if os.path.exists(font_path):
                    if font_path.endswith('.ttc'):
                        pdfmetrics.registerFont(TTFont('ChineseFont', font_path))
                    else:
                        pdfmetrics.registerFont(TTFont('ChineseFont', font_path))
                    font_name = 'ChineseFont'
                    break
            except Exception:
                continue
    except Exception:
        pass  # ä½¿ç”¨é»˜è®¤å­—ä½“
    ```
11. åœ¨åˆ›å»ºPDFæ ·å¼æ—¶ï¼Œä½¿ç”¨ fontName=font_name å‚æ•°
12. ç¡®ä¿æ‰€æœ‰å›¾è¡¨åœ¨ä¿å­˜å‰è°ƒç”¨ plt.savefig()ï¼Œä¿å­˜åè°ƒç”¨ plt.close()

**æ•°æ®ç‰¹ç‚¹è¯´æ˜ï¼š**
- æ•°æ®å¯èƒ½åŒ…å«ä¸­æ–‡åˆ—åå’Œæ–‡æœ¬æ•°æ®
- åŒ…å«æ—¥æœŸæ—¶é—´åˆ—ï¼ˆregister_date, create_time, update_timeï¼‰
- æ•°å€¼åˆ—å¯èƒ½åŒ…æ‹¬total_assets
- éœ€è¦é€‚å½“å¤„ç†éæ•°å€¼åˆ—ï¼Œé¿å…åœ¨æ•°å€¼åˆ†æä¸­å‡ºé”™

**è¾“å‡ºæ ¼å¼è¦æ±‚ï¼š**
- PDFæŠ¥å‘Šåº”è¯¥åŒ…å«ä¸­æ–‡æ–‡å­—æè¿°æ®µè½å’Œå¯¹åº”çš„è‹±æ–‡å›¾è¡¨
- æ¯ä¸ªåˆ†æéƒ¨åˆ†éƒ½åº”è¯¥æœ‰æ¸…æ™°çš„ä¸­æ–‡æ ‡é¢˜å’Œè¯¦ç»†çš„æ–‡å­—è§£é‡Š
- æ–‡å­—æè¿°åº”è¯¥ä¸“ä¸šã€å‡†ç¡®ã€æ˜“äºç†è§£
- **å›¾è¡¨ä¸­çš„æ‰€æœ‰æ–‡å­—ï¼ˆåŒ…æ‹¬åæ ‡è½´æ ‡ç­¾ã€å›¾ä¾‹ã€æ ‡é¢˜ï¼‰å¿…é¡»æ˜¯è‹±æ–‡**

è¯·åªè¿”å›Pythonä»£ç ï¼Œä¸è¦åŒ…å«ä»»ä½•è§£é‡Šæ€§æ–‡å­—ã€‚
"""
                            
                            # è°ƒç”¨å¤§æ¨¡å‹ç”Ÿæˆåˆ†æä»£ç 
                            analysis_code_response = agent.llm.invoke([HumanMessage(content=analysis_prompt)])
                            analysis_code = analysis_code_response.content.strip()
                            
                            # å¦‚æœä»£ç è¢«åŒ…è£¹åœ¨ä»£ç å—ä¸­ï¼Œæå–çº¯ä»£ç 
                            if analysis_code.startswith("```python"):
                                analysis_code = analysis_code[9:-3] if analysis_code.endswith("```") else analysis_code[9:]
                            elif analysis_code.startswith("```"):
                                analysis_code = analysis_code[3:-3] if analysis_code.endswith("```") else analysis_code[3:]
                            
                            # åœ¨æ²™ç®±ä¸­æ‰§è¡Œä»£ç 
                            result = asyncio.run(
                                execute_analysis_code(analysis_code, excel_path, report_path, timeout=120)
                            )
                            
                            if result["success"] and os.path.exists(report_path):
                                # è¯»å–PDFæ–‡ä»¶
                                with open(report_path, "rb") as f:
                                    pdf_bytes = f.read()
                                    
                                # ä¿å­˜åˆ°session stateä»¥ä¾¿ä¸‹è½½
                                report_cache_key = stable_key_for_sql(st.session_state.db_name, message['last_sql'])
                                st.session_state.analysis_reports[report_cache_key] = {
                                    'pdf_bytes': pdf_bytes,
                                    'filename': report_filename
                                }
                                
                                st.success("âœ… æ•°æ®åˆ†ææŠ¥å‘Šç”ŸæˆæˆåŠŸï¼")
                                st.download_button(
                                    label="ğŸ“¥ ä¸‹è½½æ•°æ®åˆ†ææŠ¥å‘Š (PDF)",
                                    data=pdf_bytes,
                                    file_name=report_filename,
                                    mime="application/pdf",
                                    key=f"download-report-{dl_key}"
                                )
                            else:
                                error_msg = result.get("error", "æœªçŸ¥é”™è¯¯")
                                st.error(f"âŒ æŠ¥å‘Šç”Ÿæˆå¤±è´¥: {error_msg}")
                                # æ˜¾ç¤ºç”Ÿæˆçš„ä»£ç ä»¥ä¾¿è°ƒè¯•
                                with st.expander("æŸ¥çœ‹ç”Ÿæˆçš„ä»£ç ï¼ˆç”¨äºè°ƒè¯•ï¼‰"):
                                    st.code(analysis_code, language="python")
                    
                    except Exception as e:
                        st.error(f"âŒ æŠ¥å‘Šç”Ÿæˆå‡ºé”™: {str(e)}")
                        import traceback
                        st.text(traceback.format_exc())
                    finally:
                        # æ¸…ç†ä¸´æ—¶æ–‡ä»¶
                        try:
                            if 'excel_path' in locals() and os.path.exists(excel_path):
                                os.remove(excel_path)
                            if 'report_path' in locals() and os.path.exists(report_path):
                                os.remove(report_path)
                        except Exception:
                            pass

                # å›¾è¡¨æ¸²æŸ“ï¼šä¼˜å…ˆä½¿ç”¨å·²ç¼“å­˜çš„ echarts_optionï¼Œé¿å…é‡å¤è°ƒç”¨ LLM
                if HAS_ECHARTS:
                    cached_viz = message.get("echarts_viz")
                    if cached_viz is not None:
                        # ç›´æ¥ä½¿ç”¨å·²å­˜å‚¨çš„é…ç½®
                        if cached_viz.get("show") and isinstance(cached_viz.get("option"), dict):
                            st.markdown("**ğŸ“Š å¯è§†åŒ–ï¼ˆEChartsï¼‰**")
                            st_echarts(cached_viz["option"], height="420px", key=f"chart-{dl_key}")
                        elif cached_viz.get("reason"):
                            st.caption(f"ğŸ“Š ä¸å±•ç¤ºå›¾è¡¨ï¼š{cached_viz.get('reason', 'æ•°æ®ä¸é€‚åˆ')}")
                    else:
                        # å…œåº•ï¼šä½¿ç”¨ç¼“å­˜å‡½æ•°ï¼ˆä»ç„¶å¯èƒ½è°ƒç”¨ LLMï¼Œä½†æœ‰ TTL ç¼“å­˜ï¼‰
                        try:
                            df_info = build_df_info_for_viz(df_preview, max_rows=20)
                            cache_key = f"hist-{dl_key}"
                            viz = get_cached_echarts_option(
                                cache_key=cache_key,
                                question="(å†å²æ¶ˆæ¯é‡ç»˜)",
                                sql=message.get("last_sql", ""),
                                df_info_json=json.dumps(df_info, ensure_ascii=False, default=str),
                                _agent=agent,
                            )
                            if viz.get("show") and isinstance(viz.get("option"), dict):
                                st.markdown("**ğŸ“Š å¯è§†åŒ–ï¼ˆEChartsï¼‰**")
                                st_echarts(viz["option"], height="420px", key=f"chart-{dl_key}")
                            else:
                                st.caption(f"ğŸ“Š ä¸å±•ç¤ºå›¾è¡¨ï¼š{viz.get('reason', 'æ•°æ®ä¸é€‚åˆ')}")
                        except Exception as e:
                            st.caption(f"ğŸ“Š å›¾è¡¨ç”Ÿæˆå¤±è´¥ï¼š{e}")
            except Exception as e:
                st.caption(f"âš ï¸ æŸ¥è¯¢ç»“æœå±•ç¤ºå¤±è´¥ï¼š{e}")
        
        # æ˜¾ç¤º Token ä½¿ç”¨ç»Ÿè®¡ï¼ˆå†å²æ¶ˆæ¯ï¼Œç¾åŒ–ç‰ˆï¼‰
        if message["role"] == "assistant" and message.get("token_usage"):
            token_usage = message["token_usage"]
            input_tokens = token_usage.get("input_tokens", 0)
            output_tokens = token_usage.get("output_tokens", 0)
            total_tokens = token_usage.get("total_tokens", 0) or (input_tokens + output_tokens)
            llm_calls = token_usage.get("llm_calls", 0)
            if total_tokens > 0:
                st.markdown("---")
                st.markdown("##### ğŸ“Š Token ä½¿ç”¨ç»Ÿè®¡")
                col1, col2, col3, col4 = st.columns(4)
                with col1:
                    st.metric("ğŸ“¥ è¾“å…¥", f"{input_tokens:,}")
                with col2:
                    st.metric("ğŸ“¤ è¾“å‡º", f"{output_tokens:,}")
                with col3:
                    st.metric("ğŸ“Š æ€»è®¡", f"{total_tokens:,}")
                with col4:
                    st.metric("ğŸ”„ è°ƒç”¨æ¬¡æ•°", f"{llm_calls}")
        
        # æ˜¾ç¤ºæ¶ˆæ¯å†…å®¹ï¼ˆå…è®¸åŠ©æ‰‹æ¶ˆæ¯ content ä¸ºç©ºï¼šåªå±•ç¤ºè¡¨æ ¼/ä¸‹è½½ç­‰ç»„ä»¶ï¼Œä¸é¢å¤–è¾“å‡º"æŸ¥è¯¢å®Œæˆâ€¦"æ–‡æ¡ˆï¼‰
        content = message.get("content", "")
        if isinstance(content, str) and content.strip():
            st.markdown(content)

# è¾“å…¥æ¡†
# è¾“å…¥æ¡†ï¼ˆè¿è¡Œä¸­ç¦ç”¨ï¼Œå¹¶æç¤ºâ€œæ­£åœ¨è¿è¡Œâ€ï¼‰
prompt_input = st.chat_input(
    "è¯·è¾“å…¥æ‚¨çš„é—®é¢˜..." if not st.session_state.is_running else "æ­£åœ¨æŸ¥è¯¢ä¸­ï¼Œè¯·ç¨å€™â€¦",
    disabled=bool(st.session_state.is_running),
)

# ç¬¬ä¸€æ­¥ï¼šç”¨æˆ·æäº¤åå…ˆç¼“å­˜ prompt å¹¶ rerunï¼Œä½¿è¾“å…¥æ¡†ç«‹å³è¿›å…¥â€œè¿è¡Œä¸­â€çŠ¶æ€ï¼ˆæ›´é¡ºæ»‘ï¼‰
if prompt_input:
    st.session_state.pending_prompt = prompt_input
    st.session_state.is_running = True
    st.rerun()

# ç¬¬äºŒæ­¥ï¼šå¦‚æœæœ‰å¾…å¤„ç† prompt ä¸” is_running=Trueï¼Œå°±æ‰§è¡ŒæŸ¥è¯¢
if st.session_state.pending_prompt and st.session_state.is_running:
    prompt = st.session_state.pending_prompt

    # æ·»åŠ ç”¨æˆ·æ¶ˆæ¯ï¼ˆåªæ·»åŠ ä¸€æ¬¡ï¼‰
    st.session_state.messages.append({"role": "user", "content": prompt})
    current_conv["updated_at"] = time.time()
    with st.chat_message("user"):
        st.markdown(prompt)

    with st.chat_message("assistant"):
        # å·¥å…·è°ƒç”¨æµç¨‹å±•ç¤ºï¼ˆé»˜è®¤æŠ˜å ï¼Œç”¨æˆ·ç‚¹å‡»å¯å±•å¼€æŸ¥çœ‹è¯¦æƒ…ï¼‰
        status_box = st.status("æ­£åœ¨æ‰§è¡ŒæŸ¥è¯¢...", expanded=False, state="running")
        live_handler = StreamlitStatusTraceHandler(status_box)

        tool_result = agent.run_tools(prompt, callbacks=[live_handler])

        if tool_result.get("success"):
            status_box.update(label="æŸ¥è¯¢æ‰§è¡ŒæˆåŠŸï¼ˆç‚¹å‡»å±•å¼€è¯¦æƒ…ï¼‰", state="complete", expanded=False)
        else:
            status_box.update(label="æŸ¥è¯¢æ‰§è¡Œå¤±è´¥ï¼ˆç‚¹å‡»æŸ¥çœ‹è¯¦æƒ…ï¼‰", state="error", expanded=False)

        df = None
        full_count = None
        echarts_viz = None  # ç”¨äºç¼“å­˜åˆ°æ¶ˆæ¯

        if tool_result.get("success"):
            if tool_result.get("sql"):
                # ä¼˜å…ˆå±•ç¤ºæŒ‰ç”¨æˆ·æ„å›¾ç”Ÿæˆçš„â€œä¸‹è½½ SQLâ€
                display_sql = None
                if "download_sql" in locals():
                    display_sql = download_sql
                with st.expander("ğŸ“ æŸ¥çœ‹ç”Ÿæˆçš„ SQL è¯­å¥", expanded=False):
                    st.code(display_sql or tool_result["sql"], language="sql")

            last_sql = tool_result.get("last_sql", "") or ""
            if last_sql:
                try:
                    engine = get_sqlalchemy_engine(st.session_state.db_name)
                    
                    # è®¡ç®—"å…¨é‡è¡Œæ•°"ï¼šå¯¹å»æ‰ LIMIT çš„ SQL åš COUNT(*)
                    try:
                        sql_no_limit = strip_trailing_limit(last_sql)
                        count_sql = f"SELECT COUNT(*) FROM ({sql_no_limit}) AS t"
                        full_count = int(execute_scalar(count_sql, engine))
                    except Exception:
                        full_count = None
                    
                    # é¢„è§ˆç”¨ SQLï¼ˆå›ºå®šæœ€å¤š50è¡Œï¼‰ï¼šå…ˆå»æ‰åŸ LIMITï¼Œå†å¼ºåˆ¶åŠ  LIMIT 50
                    preview_limit = 50
                    sql_no_limit_preview = strip_trailing_limit(last_sql)
                    preview_sql = sanitize_sql_query(sql_no_limit_preview, default_limit=preview_limit, hard_limit=preview_limit)
                    df_preview = execute_sql_to_df(preview_sql, engine)

                    # æ˜¾ç¤ºé¢„è§ˆè¡¨æ ¼
                    if full_count is not None and full_count <= preview_limit:
                        st.markdown(f"**ğŸ“„ æŸ¥è¯¢ç»“æœï¼ˆå…± {full_count} è¡Œï¼Œå·²å…¨éƒ¨å±•ç¤ºï¼‰**")
                    elif full_count is not None:
                        st.markdown(f"**ğŸ“„ æŸ¥è¯¢ç»“æœï¼ˆå‰ {len(df_preview)} è¡Œ / å…± {full_count} è¡Œï¼‰**")
                    else:
                        st.markdown(f"**ğŸ“„ æŸ¥è¯¢ç»“æœï¼ˆå‰ {len(df_preview)} è¡Œï¼‰**")
                    st.dataframe(df_preview, use_container_width=True)

                    # ä¸‹è½½ï¼šæŒ‰ç”¨æˆ·æ„å›¾å†³å®šè¡Œæ•°ï¼ˆè§„åˆ™ä¼˜å…ˆ + LLM å…œåº•ï¼‰
                    intent_limit = resolve_download_limit(prompt, agent.llm)
                    if intent_limit is None:
                        download_sql = last_sql
                    elif intent_limit >= LIMIT_ALL:
                        download_sql = strip_trailing_limit(last_sql)
                    else:
                        download_sql = sanitize_sql_query(
                            last_sql, default_limit=intent_limit, hard_limit=intent_limit
                        )
                    df_download = execute_sql_to_df(download_sql, engine)
                    excel_bytes = build_excel_bytes(df_download)
                    filename = f"query_result_{datetime.now().strftime('%Y%m%d_%H%M%S')}.xlsx"
                    download_rows = len(df_download)
                    st.download_button(
                        label=f"â¬‡ï¸ ä¸‹è½½ç»“æœï¼ˆExcelï¼Œå…± {download_rows} è¡Œï¼‰",
                        data=excel_bytes,
                        file_name=filename,
                        mime="application/vnd.openxmlformats-officedocument.spreadsheetml.sheet",
                        key=f"download-live-{stable_key_for_sql(st.session_state.db_name, download_sql)}",
                    )

                    # æ–°å¢ï¼šè‡ªå®šä¹‰åˆ†æè¦æ±‚è¾“å…¥æ¡†ï¼ˆå®æ—¶æŸ¥è¯¢ç»“æœï¼‰
                    custom_analysis_req_live = st.text_input(
                        "ğŸ“Š è‡ªå®šä¹‰åˆ†æè¦æ±‚ï¼ˆå¯é€‰ï¼‰:",
                        key=f"custom-analysis-req-live-{stable_key_for_sql(st.session_state.db_name, download_sql)}",
                        placeholder="ä¾‹å¦‚ï¼šé‡ç‚¹å…³æ³¨é”€å”®é¢è¶‹åŠ¿ã€æŒ‰åœ°åŒºåˆ†ç»„ç»Ÿè®¡ã€ç”Ÿæˆç›¸å…³æ€§çƒ­åŠ›å›¾ç­‰"
                    )

                    # æ–°å¢ï¼šç”Ÿæˆæ•°æ®åˆ†ææŠ¥å‘ŠæŒ‰é’®ï¼ˆå®æ—¶æŸ¥è¯¢ç»“æœï¼‰
                    live_report_key = f"live-report-{stable_key_for_sql(st.session_state.db_name, download_sql)}"
                    if st.button("ğŸ“Š ç”Ÿæˆæ•°æ®åˆ†ææŠ¥å‘Š", key=f"generate-live-report-{stable_key_for_sql(st.session_state.db_name, download_sql)}"):
                        try:
                            with st.spinner("æ­£åœ¨ç”Ÿæˆæ•°æ®åˆ†ææŠ¥å‘Š..."):
                                # ä¿å­˜å½“å‰åˆ†ææ‰€éœ€çš„æ•°æ®
                                st.session_state.current_analysis_df = df_download.copy()
                                st.session_state.current_analysis_question = prompt
                                
                                # ç”ŸæˆExcelæ–‡ä»¶ç”¨äºæ²™ç®±æ‰§è¡Œ
                                excel_filename = f"temp_data_{datetime.now().strftime('%Y%m%d_%H%M%S')}.xlsx"
                                excel_path = f"/tmp/{excel_filename}"
                                df_download.to_excel(excel_path, index=False)
                                
                                # ç”ŸæˆPDFæŠ¥å‘Šæ–‡ä»¶è·¯å¾„
                                report_filename = f"analysis_report_{datetime.now().strftime('%Y%m%d_%H%M%S')}.pdf"
                                report_path = f"/tmp/{report_filename}"
                                
                                # æ„å»ºåˆ†ææç¤ºè¯
                                base_prompt = f"""
ä½ æ˜¯ä¸€åä¸“ä¸šçš„æ•°æ®ç§‘å­¦å®¶ã€‚è¯·åŸºäºç”¨æˆ·çš„é—®é¢˜å’Œæä¾›çš„DataFrameï¼ˆå˜é‡å: dfï¼‰ç”Ÿæˆå®Œæ•´çš„Pythonæ•°æ®åˆ†æä»£ç ã€‚

ç”¨æˆ·é—®é¢˜: {prompt}
"""
                                
                                if custom_analysis_req_live.strip():
                                    base_prompt += f"\nç”¨æˆ·è‡ªå®šä¹‰åˆ†æè¦æ±‚: {custom_analysis_req_live.strip()}\n"
                                
                                analysis_prompt = base_prompt + f"""
è¦æ±‚ï¼š
1. è¿›è¡Œå…¨é¢çš„æ•°æ®åˆ†æï¼ŒåŒ…æ‹¬åŸºæœ¬ç»Ÿè®¡ã€ç›¸å…³æ€§åˆ†æã€åˆ†å¸ƒåˆ†æç­‰
2. ç”Ÿæˆé«˜è´¨é‡çš„å¯è§†åŒ–å›¾è¡¨ï¼ˆä½¿ç”¨matplotlib/seabornï¼‰ï¼Œ**æ‰€æœ‰å›¾è¡¨æ ‡é¢˜ã€æ ‡ç­¾ã€å›¾ä¾‹å¿…é¡»ä½¿ç”¨è‹±æ–‡**
3. å°†æ‰€æœ‰åˆ†æç»“æœæ•´åˆåˆ°ä¸€ä¸ªPDFæŠ¥å‘Šä¸­ï¼Œ**åŒ…å«è¯¦ç»†çš„ä¸­æ–‡æ–‡å­—æè¿°å’Œè§£é‡Š**
4. PDFæŠ¥å‘Šå¿…é¡»ä¿å­˜åˆ°è·¯å¾„: {report_path}
5. **ä¸­æ–‡æ–‡å­—æè¿°å†…å®¹åº”åŒ…æ‹¬**ï¼š
   - æ•°æ®æ¦‚è§ˆï¼ˆå½¢çŠ¶ã€åˆ—ä¿¡æ¯ã€æ•°æ®ç±»å‹ï¼‰
   - ç¼ºå¤±å€¼åˆ†æ
   - åŸºæœ¬ç»Ÿè®¡æ‘˜è¦
   - æ•°å€¼åˆ—çš„åˆ†å¸ƒç‰¹å¾åˆ†æ
   - åˆ†ç±»åˆ—çš„é¢‘æ¬¡åˆ†æ  
   - ç›¸å…³æ€§åˆ†æï¼ˆå¦‚æœé€‚ç”¨ï¼‰
   - å…³é”®å‘ç°å’Œæ´å¯Ÿæ€»ç»“
6. ä¸è¦ä½¿ç”¨plt.show()ï¼Œç›´æ¥ä¿å­˜å›¾è¡¨åˆ°PDF
7. ç¡®ä¿ä»£ç å®Œæ•´å¯è¿è¡Œï¼ŒåŒ…å«æ‰€æœ‰å¿…è¦çš„importè¯­å¥
8. **é‡è¦ï¼šå¤„ç†ä¸­æ–‡æ ‡ç­¾æ—¶ä½¿ç”¨æä¾›çš„è½¬æ¢å‡½æ•°**ï¼š
   ```python
   # å¦‚æœæ‚¨çš„æ•°æ®åŒ…å«ä¸­æ–‡åˆ†ç±»æ ‡ç­¾ï¼Œä½¿ç”¨ä»¥ä¸‹å‡½æ•°è½¬æ¢ä¸ºè‹±æ–‡
   # x_labels = safe_translate_labels(original_labels)
   # ax.set_xticklabels(x_labels)
   
   # æˆ–è€…åœ¨åˆ›å»ºå›¾è¡¨æ—¶ç›´æ¥è½¬æ¢
   # categories = [translate_chinese_to_english(cat) for cat in original_categories]
   ```
9. **å¿…é¡»åŒ…å«matplotlibè‹±æ–‡é…ç½®**ï¼š
   ```python
   import matplotlib.pyplot as plt
   import matplotlib
   matplotlib.rcParams['font.sans-serif'] = ['DejaVu Sans', 'Arial', 'Helvetica']
   matplotlib.rcParams['axes.unicode_minus'] = False
   ```
10. **å¿…é¡»åŒ…å«reportlabä¸­æ–‡å­—ä½“é…ç½®**ï¼š
    ```python
    from reportlab.pdfbase import pdfmetrics
    from reportlab.pdfbase.ttfonts import TTFont
    import os
    
    # æ³¨å†Œä¸­æ–‡å­—ä½“ç”¨äºPDFæ–‡å­—æè¿°
    font_name = 'Helvetica'
    try:
        font_paths_to_try = [
            '/usr/share/fonts/truetype/wqy/wqy-zenhei.ttc',
            '/usr/share/fonts/truetype/wqy/wqy-microhei.ttc',
            '/usr/share/fonts/truetype/dejavu/DejaVuSans.ttf'
        ]
        
        for font_path in font_paths_to_try:
            try:
                if os.path.exists(font_path):
                    if font_path.endswith('.ttc'):
                        pdfmetrics.registerFont(TTFont('ChineseFont', font_path))
                    else:
                        pdfmetrics.registerFont(TTFont('ChineseFont', font_path))
                    font_name = 'ChineseFont'
                    break
            except Exception:
                continue
    except Exception:
        pass  # ä½¿ç”¨é»˜è®¤å­—ä½“
    ```
11. åœ¨åˆ›å»ºPDFæ ·å¼æ—¶ï¼Œä½¿ç”¨ fontName=font_name å‚æ•°
12. ç¡®ä¿æ‰€æœ‰å›¾è¡¨åœ¨ä¿å­˜å‰è°ƒç”¨ plt.savefig()ï¼Œä¿å­˜åè°ƒç”¨ plt.close()

**æ•°æ®ç‰¹ç‚¹è¯´æ˜ï¼š**
- æ•°æ®å¯èƒ½åŒ…å«ä¸­æ–‡åˆ—åå’Œæ–‡æœ¬æ•°æ®
- åŒ…å«æ—¥æœŸæ—¶é—´åˆ—ï¼ˆregister_date, create_time, update_timeï¼‰
- æ•°å€¼åˆ—å¯èƒ½åŒ…æ‹¬total_assets
- éœ€è¦é€‚å½“å¤„ç†éæ•°å€¼åˆ—ï¼Œé¿å…åœ¨æ•°å€¼åˆ†æä¸­å‡ºé”™

**è¾“å‡ºæ ¼å¼è¦æ±‚ï¼š**
- PDFæŠ¥å‘Šåº”è¯¥åŒ…å«ä¸­æ–‡æ–‡å­—æè¿°æ®µè½å’Œå¯¹åº”çš„è‹±æ–‡å›¾è¡¨
- æ¯ä¸ªåˆ†æéƒ¨åˆ†éƒ½åº”è¯¥æœ‰æ¸…æ™°çš„ä¸­æ–‡æ ‡é¢˜å’Œè¯¦ç»†çš„æ–‡å­—è§£é‡Š
- æ–‡å­—æè¿°åº”è¯¥ä¸“ä¸šã€å‡†ç¡®ã€æ˜“äºç†è§£
- **å›¾è¡¨ä¸­çš„æ‰€æœ‰æ–‡å­—ï¼ˆåŒ…æ‹¬åæ ‡è½´æ ‡ç­¾ã€å›¾ä¾‹ã€æ ‡é¢˜ï¼‰å¿…é¡»æ˜¯è‹±æ–‡**

è¯·åªè¿”å›Pythonä»£ç ï¼Œä¸è¦åŒ…å«ä»»ä½•è§£é‡Šæ€§æ–‡å­—ã€‚
"""
                                
                                # è°ƒç”¨å¤§æ¨¡å‹ç”Ÿæˆåˆ†æä»£ç 
                                analysis_code_response = agent.llm.invoke([HumanMessage(content=analysis_prompt)])
                                analysis_code = analysis_code_response.content.strip()
                                
                                # å¦‚æœä»£ç è¢«åŒ…è£¹åœ¨ä»£ç å—ä¸­ï¼Œæå–çº¯ä»£ç 
                                if analysis_code.startswith("```python"):
                                    analysis_code = analysis_code[9:-3] if analysis_code.endswith("```") else analysis_code[9:]
                                elif analysis_code.startswith("```"):
                                    analysis_code = analysis_code[3:-3] if analysis_code.endswith("```") else analysis_code[3:]
                                
                                # åœ¨æ²™ç®±ä¸­æ‰§è¡Œä»£ç 
                                result = asyncio.run(
                                    execute_analysis_code(analysis_code, excel_path, report_path, timeout=120)
                                )
                                
                                if result["success"] and os.path.exists(report_path):
                                    # è¯»å–PDFæ–‡ä»¶
                                    with open(report_path, "rb") as f:
                                        pdf_bytes = f.read()
                                        
                                    # ä¿å­˜åˆ°session stateä»¥ä¾¿ä¸‹è½½
                                    report_cache_key = stable_key_for_sql(st.session_state.db_name, download_sql)
                                    st.session_state.analysis_reports[report_cache_key] = {
                                        'pdf_bytes': pdf_bytes,
                                        'filename': report_filename
                                    }
                                    
                                    st.success("âœ… æ•°æ®åˆ†ææŠ¥å‘Šç”ŸæˆæˆåŠŸï¼")
                                    st.download_button(
                                        label="ğŸ“¥ ä¸‹è½½æ•°æ®åˆ†ææŠ¥å‘Š (PDF)",
                                        data=pdf_bytes,
                                        file_name=report_filename,
                                        mime="application/pdf",
                                        key=f"download-live-report-{stable_key_for_sql(st.session_state.db_name, download_sql)}"
                                    )
                                else:
                                    error_msg = result.get("error", "æœªçŸ¥é”™è¯¯")
                                    st.error(f"âŒ æŠ¥å‘Šç”Ÿæˆå¤±è´¥: {error_msg}")
                                    # æ˜¾ç¤ºç”Ÿæˆçš„ä»£ç ä»¥ä¾¿è°ƒè¯•
                                    with st.expander("æŸ¥çœ‹ç”Ÿæˆçš„ä»£ç ï¼ˆç”¨äºè°ƒè¯•ï¼‰"):
                                        st.code(analysis_code, language="python")
                        
                        except Exception as e:
                            st.error(f"âŒ æŠ¥å‘Šç”Ÿæˆå‡ºé”™: {str(e)}")
                            import traceback
                            st.text(traceback.format_exc())
                        finally:
                            # æ¸…ç†ä¸´æ—¶æ–‡ä»¶
                            try:
                                if 'excel_path' in locals() and os.path.exists(excel_path):
                                    os.remove(excel_path)
                                if 'report_path' in locals() and os.path.exists(report_path):
                                    os.remove(report_path)
                            except Exception:
                                pass

                    # å¯è§†åŒ–ç”Ÿæˆï¼ˆä½¿ç”¨é¢„è§ˆæ•°æ®ï¼‰
                    if HAS_ECHARTS:
                        chart_placeholder = st.empty()
                        chart_placeholder.info("æ­£åœ¨ç”Ÿæˆå¯è§†åŒ–å›¾è¡¨...")
                        
                        try:
                            df_info = build_df_info_for_viz(df_preview, max_rows=20)
                            viz = agent.generate_echarts_option(
                                question=prompt,
                                sql=tool_result.get("sql", ""),
                                df_info=df_info,
                            )
                            echarts_viz = viz  # ç¼“å­˜åˆ°æ¶ˆæ¯
                            
                            chart_placeholder.empty()  # æ¸…é™¤ loading æç¤º
                            if viz.get("show") and isinstance(viz.get("option"), dict):
                                st.markdown("**ğŸ“Š å¯è§†åŒ–ï¼ˆEChartsï¼‰**")
                                st_echarts(viz["option"], height="420px", key=f"chart-live-{stable_key_for_sql(st.session_state.db_name, preview_sql)}")
                            else:
                                st.caption(f"ğŸ“Š ä¸å±•ç¤ºå›¾è¡¨ï¼š{viz.get('reason', 'æ•°æ®ä¸é€‚åˆ')}")
                        except Exception as e:
                            chart_placeholder.empty()
                            st.caption(f"ğŸ“Š å›¾è¡¨ç”Ÿæˆå¤±è´¥ï¼š{e}")
                            echarts_viz = {"show": False, "reason": str(e)}
                    else:
                        st.caption("ğŸ“Š æœªå®‰è£… `streamlit-echarts`ï¼Œæš‚ä¸å±•ç¤ºå›¾è¡¨ã€‚")
                except Exception as e:
                    st.caption(f"âš ï¸ æŸ¥è¯¢ç»“æœå±•ç¤ºå¤±è´¥ï¼š{e}")
            else:
                st.caption("âš ï¸ æœªæ•è·åˆ°å¯ç”¨äºå±•ç¤ºçš„æ•°æ®æŸ¥è¯¢ SQLï¼ˆlast_sql ä¸ºç©ºï¼‰ã€‚")

            # æ˜¾ç¤º Token ä½¿ç”¨ç»Ÿè®¡ï¼ˆç¾åŒ–ç‰ˆï¼‰
            token_usage = tool_result.get("token_usage")
            if token_usage:
                input_tokens = token_usage.get("input_tokens", 0)
                output_tokens = token_usage.get("output_tokens", 0)
                total_tokens = token_usage.get("total_tokens", 0) or (input_tokens + output_tokens)
                llm_calls = token_usage.get("llm_calls", 0)
                if total_tokens > 0:
                    st.markdown("---")
                    st.markdown("##### ğŸ“Š Token ä½¿ç”¨ç»Ÿè®¡")
                    col1, col2, col3, col4 = st.columns(4)
                    with col1:
                        st.metric("ğŸ“¥ è¾“å…¥", f"{input_tokens:,}")
                    with col2:
                        st.metric("ğŸ“¤ è¾“å‡º", f"{output_tokens:,}")
                    with col3:
                        st.metric("ğŸ“Š æ€»è®¡", f"{total_tokens:,}")
                    with col4:
                        st.metric("ğŸ”„ è°ƒç”¨æ¬¡æ•°", f"{llm_calls}")

            # ä¿å­˜åˆ°æ¶ˆæ¯å†å²ï¼šä¿å­˜ last_sql + effective_limit + full_count + echarts_viz + trace
            msg = {"role": "assistant", "content": "", "question": prompt}
            if tool_result.get("sql"):
                msg["sql"] = tool_result["sql"]
            if "download_sql" in locals():
                msg["download_sql"] = download_sql
            if tool_result.get("last_sql"):
                msg["last_sql"] = tool_result["last_sql"]
            msg["effective_limit"] = int(tool_result.get("effective_limit") or 20)
            if full_count is not None:
                msg["full_count"] = int(full_count)
            if echarts_viz is not None:
                msg["echarts_viz"] = echarts_viz  # ç¼“å­˜å›¾è¡¨é…ç½®ï¼Œå†å²æ¸²æŸ“æ—¶ç›´æ¥ä½¿ç”¨
            if tool_result.get("trace"):
                msg["trace"] = tool_result["trace"]  # ä¿å­˜å·¥å…·è°ƒç”¨è½¨è¿¹
            if tool_result.get("token_usage"):
                msg["token_usage"] = tool_result["token_usage"]  # ä¿å­˜ token ä½¿ç”¨ç»Ÿè®¡
            st.session_state.messages.append(msg)
            current_conv["updated_at"] = time.time()
        else:
            error_msg = f"âŒ æŸ¥è¯¢å¤±è´¥: {tool_result.get('error', 'æœªçŸ¥é”™è¯¯')}"
            st.error(error_msg)
            # å¤±è´¥æ—¶ä¹Ÿæ˜¾ç¤ºå·²æ¶ˆè€—çš„ tokenï¼ˆç®€æ´ç‰ˆï¼‰
            token_usage = tool_result.get("token_usage")
            if token_usage:
                total_tokens = token_usage.get("total_tokens", 0)
                llm_calls = token_usage.get("llm_calls", 0)
                if total_tokens > 0:
                    st.info(f"ğŸ“Š å·²æ¶ˆè€— Tokenï¼š**{total_tokens:,}**ï¼ˆ{llm_calls} æ¬¡è°ƒç”¨ï¼‰")
            st.session_state.messages.append({"role": "assistant", "content": error_msg})
            current_conv["updated_at"] = time.time()

    # æ¸…ç†è¿è¡Œæ ‡è®°å¹¶ rerunï¼Œæ¢å¤è¾“å…¥æ¡†
    st.session_state.pending_prompt = None
    st.session_state.is_running = False
    st.rerun()

# ï¼ˆå·²ç§»é™¤ï¼‰ç¤ºä¾‹é—®é¢˜ã€ç³»ç»Ÿä¿¡æ¯ï¼šä¿æŒèŠå¤©ç•Œé¢ç®€æ´
