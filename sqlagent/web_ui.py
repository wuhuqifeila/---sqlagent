"""
åŸºäº Streamlit çš„ SQL Agent Web ç•Œé¢
æä¾›èŠå¤©å¼äº¤äº’å’Œç»“æœå¯è§†åŒ–
"""
import streamlit as st
import sys
import os
import json
from io import BytesIO
from datetime import datetime
from typing import Any, Dict, List, Optional
from langchain_core.callbacks import BaseCallbackHandler
import time
import pandas as pd
from sqlalchemy import create_engine
import hashlib
import re

# æ·»åŠ é¡¹ç›®æ ¹ç›®å½•åˆ° Python è·¯å¾„
sys.path.insert(0, os.path.dirname(os.path.dirname(os.path.abspath(__file__))))

from sqlagent import SQLAgent, Config
from sqlagent.security import sanitize_sql_query, MAX_HARD_LIMIT

# EChartsï¼ˆå¯é€‰ä¾èµ–ï¼Œæœªå®‰è£…æ—¶è‡ªåŠ¨é™çº§ä¸æ˜¾ç¤ºå›¾è¡¨ï¼‰
try:
    from streamlit_echarts import st_echarts  # type: ignore
    HAS_ECHARTS = True
except Exception:
    HAS_ECHARTS = False


class StreamlitStatusTraceHandler(BaseCallbackHandler):
    """æŠŠå·¥å…·è°ƒç”¨è¿‡ç¨‹å®æ—¶å†™åˆ° Streamlit çš„ st.statusï¼Œå±•ç¤ºå®Œæ•´æ‰§è¡Œæµç¨‹ã€‚"""

    def __init__(self, status_box):
        self.status_box = status_box
        self.step_no = 0
        self._current_tool: Optional[str] = None

    @staticmethod
    def _norm(v: Any) -> str:
        if v is None:
            return ""
        if isinstance(v, str):
            return v.strip()
        if isinstance(v, dict):
            # å¸¸è§ï¼š{"query": "..."} / {"tool_input": "..."}
            if "query" in v and isinstance(v["query"], str):
                return v["query"].strip()
            if "tool_input" in v and isinstance(v["tool_input"], str):
                return v["tool_input"].strip()
            return str(v)
        return str(v).strip()

    def on_tool_start(self, serialized: Dict[str, Any], input_str: Any = None, **kwargs) -> None:
        tool_name = (serialized or {}).get("name") or kwargs.get("name") or ""
        normalized_input = self._norm(input_str if input_str is not None else kwargs.get("input"))

        self.step_no += 1
        self._current_tool = tool_name
        
        # æ˜¾ç¤ºå·¥å…·è°ƒç”¨ä¿¡æ¯
        self.status_box.write(f"**{self.step_no}. è°ƒç”¨å·¥å…·ï¼š`{tool_name}`**")
        if normalized_input:
            if tool_name == "sql_db_query":
                self.status_box.write("è¾“å…¥ï¼ˆSQLï¼‰ï¼š")
                self.status_box.code(normalized_input, language="sql")
            else:
                self.status_box.write("è¾“å…¥ï¼š")
                self.status_box.code(normalized_input)

    def on_tool_end(self, output: Any, **kwargs) -> None:
        normalized_output = self._norm(output)
        if normalized_output:
            self.status_box.write("è¾“å‡ºï¼š")
            self.status_box.code(normalized_output)

    def on_tool_error(self, error: Exception, **kwargs) -> None:
        self.status_box.write(f"âŒ å·¥å…·æ‰§è¡Œå‡ºé”™ï¼š{error}")


class StreamlitAnswerStreamHandler(BaseCallbackHandler):
    """åªç”¨äºâ€œæœ€ç»ˆå›ç­”â€çš„ token æµå¼å±•ç¤ºã€‚"""

    def __init__(self, placeholder: "st.delta_generator.DeltaGenerator"):
        self.placeholder = placeholder
        self._buf: List[str] = []
        self._last_flush = 0.0

    def on_llm_new_token(self, token: str, **kwargs) -> None:
        self._buf.append(token)
        now = time.monotonic()
        # è½»å¾®èŠ‚æµï¼Œé¿å…æ¯ä¸ª token éƒ½è§¦å‘ UI é‡ç»˜
        if now - self._last_flush >= 0.05:
            self.placeholder.markdown("".join(self._buf))
            self._last_flush = now

    def flush(self) -> str:
        text = "".join(self._buf)
        self.placeholder.markdown(text)
        return text


@st.cache_resource
def get_sqlalchemy_engine(db_name: str):
    """å¤ç”¨ SQLAlchemy Engineï¼ˆé¿å…æ¯æ¬¡éƒ½æ–°å»ºè¿æ¥æ± ï¼‰ã€‚"""
    uri = Config.get_db_uri(db_name)
    engine_args = {
        "pool_pre_ping": True,
        "pool_size": 5,
        "max_overflow": 10,
        "pool_recycle": 3600,
        "connect_args": {"connect_timeout": 10},
    }
    return create_engine(uri, **engine_args)




def build_excel_bytes(df: pd.DataFrame) -> bytes:
    buf = BytesIO()
    with pd.ExcelWriter(buf, engine="openpyxl") as writer:
        df.to_excel(writer, index=False, sheet_name="result")
    return buf.getvalue()

def df_preview_text(df: pd.DataFrame, n: int = 20) -> str:
    """ç»™æ¨¡å‹ç”¨çš„æ ·ä¾‹æ–‡æœ¬ï¼šæœ€å¤š n è¡Œï¼Œé¿å…ä¸Šä¸‹æ–‡çˆ†ç‚¸ã€‚"""
    if df is None or df.empty:
        return "(ç©ºç»“æœ)"
    d = df.head(n).copy()
    # å…¨éƒ¨è½¬æˆå­—ç¬¦ä¸²ï¼Œé¿å… datetime/decimal ç­‰åœ¨ markdown é‡Œè¿‡é•¿
    for c in d.columns:
        d[c] = d[c].astype(str)
    try:
        return d.to_markdown(index=False)
    except Exception:
        # å…œåº•ï¼šCSV
        return d.to_csv(index=False)

@st.cache_data(ttl=300, show_spinner=False)
def get_df_for_sql(db_name: str, sql: str) -> pd.DataFrame:
    """ä¸ºå†å²æ¶ˆæ¯é‡ç»˜/ä¸‹è½½é‡è·‘æä¾› DataFrameï¼ˆå¸¦ç¼“å­˜ï¼Œé¿å…é¢‘ç¹æ‰“åº“ï¼‰ã€‚"""
    engine = get_sqlalchemy_engine(db_name)
    return execute_sql_to_df(sql, engine)

def stable_key_for_sql(db_name: str, sql: str) -> str:
    raw = (db_name + "\n" + (sql or "")).encode("utf-8", errors="ignore")
    return hashlib.md5(raw).hexdigest()


# ç¼“å­˜å›¾è¡¨é…ç½®ï¼Œé¿å…å†å²æ¶ˆæ¯é‡å¤è°ƒç”¨ LLM
@st.cache_data(ttl=600, show_spinner=False)
def get_cached_echarts_option(cache_key: str, question: str, sql: str, df_info_json: str, _agent) -> Dict[str, Any]:
    """ç¼“å­˜ ECharts é…ç½®ç”Ÿæˆç»“æœï¼Œé¿å…å†å²æ¶ˆæ¯æ¯æ¬¡ rerun éƒ½é‡æ–°è°ƒç”¨ LLMã€‚"""
    import json
    df_info = json.loads(df_info_json) if df_info_json else {}
    return _agent.generate_echarts_option(question=question, sql=sql, df_info=df_info)

def build_df_info_for_viz(df: pd.DataFrame, max_rows: int = 20) -> Dict[str, Any]:
    """ç»™ LLM ç”¨çš„å¯è§†åŒ–ä¸Šä¸‹æ–‡ï¼šé¿å…å¡å…¨é‡ï¼Œæä¾›åˆ—ç±»å‹/åŸºæ•°/æ ·ä¾‹/ç®€å•ç»Ÿè®¡ã€‚"""
    if df is None or df.empty:
        return {"row_count": 0, "columns": [], "sample_rows": []}

    d = df.copy().head(max_rows)

    cols_info: List[Dict[str, Any]] = []
    for c in d.columns:
        s = d[c]
        # åŸºæœ¬ç±»å‹
        if pd.api.types.is_numeric_dtype(s):
            col_type = "number"
        elif pd.api.types.is_datetime64_any_dtype(s):
            col_type = "datetime"
        else:
            col_type = "string"

        nunique = int(s.astype(str).nunique(dropna=True))
        cols_info.append(
            {
                "name": str(c),
                "type": col_type,
                "nunique": nunique,
            }
        )

    # æ ·ä¾‹è¡Œï¼šè½¬æˆçº¯ Python ç±»å‹ï¼Œé¿å… datetime/decimal åºåˆ—åŒ–é—®é¢˜
    sample_rows = d.astype(str).to_dict(orient="records")

    # æ•°å€¼åˆ—ç®€å•ç»Ÿè®¡
    num_cols = [c for c in d.columns if pd.api.types.is_numeric_dtype(d[c])]
    numeric_summary: Dict[str, Any] = {}
    for c in num_cols[:5]:
        s = pd.to_numeric(d[c], errors="coerce")
        numeric_summary[str(c)] = {
            "min": float(s.min()) if s.notna().any() else None,
            "max": float(s.max()) if s.notna().any() else None,
            "mean": float(s.mean()) if s.notna().any() else None,
        }

    return {
        "row_count": int(len(df)),
        "columns": cols_info,
        "sample_rows": sample_rows,
        "numeric_summary": numeric_summary,
        "note": f"sample_rows ä»…ä¸ºå‰ {max_rows} è¡Œï¼Œç”¨äºé€‰å›¾ï¼›çœŸå®ç»“æœè¡Œæ•°è§ row_countã€‚",
    }

def execute_sql_to_df(sql: str, engine) -> pd.DataFrame:
    """
    ä½¿ç”¨ SQLAlchemy çš„ raw_connection è·å– DBAPI è¿æ¥ç›´æ¥æ‰§è¡Œ SQLï¼Œ
    è§„é¿æŸäº›é©±åŠ¨åœ¨åŒ…å« LIKE '%xx%' æ—¶æŠŠ % è¯¯å½“ä½œå ä½ç¬¦å¯¼è‡´çš„æ ¼å¼åŒ–é”™è¯¯ã€‚
    """
    q = (sql or "").strip().rstrip(";")
    if not q:
        return pd.DataFrame()

    conn = engine.raw_connection()
    try:
        cur = conn.cursor()
        cur.execute(q)  # ä¸ä¼ å‚æ•°ï¼Œç¡®ä¿ % ä½œä¸º SQL å­—é¢é‡ç”Ÿæ•ˆ
        rows = cur.fetchall()
        cols = [d[0] for d in (cur.description or [])]
        return pd.DataFrame(list(rows), columns=cols)
    finally:
        try:
            conn.close()
        except Exception:
            pass


def execute_scalar(sql: str, engine) -> Any:
    """æ‰§è¡Œè¿”å›å•ä¸ªå€¼çš„ SQLï¼ˆä¾‹å¦‚ COUNT(*)ï¼‰ã€‚"""
    q = (sql or "").strip().rstrip(";")
    if not q:
        return None
    conn = engine.raw_connection()
    try:
        cur = conn.cursor()
        cur.execute(q)
        row = cur.fetchone()
        return row[0] if row else None
    finally:
        try:
            conn.close()
        except Exception:
            pass


def strip_trailing_limit(sql: str) -> str:
    """
    å»é™¤æœ«å°¾ LIMIT å­å¥ï¼ˆä»…å¤„ç†æœ«å°¾çš„ LIMIT n / LIMIT offset,n / LIMIT n OFFSET offsetï¼‰ã€‚
    ç”¨äºè®¡ç®—â€œå…¨é‡è¡Œæ•°â€COUNT(*)ã€‚
    """
    s = (sql or "").strip().rstrip(";")
    # ç§»é™¤æœ«å°¾ LIMIT ...ï¼ˆå°½é‡ä¸å½±å“å­æŸ¥è¯¢å†… LIMITï¼‰
    s = re.sub(r"(?is)\s+limit\s+\d+\s*,\s*\d+\s*$", "", s)
    s = re.sub(r"(?is)\s+limit\s+\d+\s+offset\s+\d+\s*$", "", s)
    s = re.sub(r"(?is)\s+limit\s+\d+\s*$", "", s)
    return s.strip()


def auto_echarts_option(df: pd.DataFrame) -> Optional[Dict[str, Any]]:
    """æ ¹æ® df çš„åˆ—ç±»å‹è‡ªåŠ¨é€‰æ‹©ä¸€ä¸ªåˆé€‚çš„ ECharts optionï¼ˆç®€å•è§„åˆ™ç‰ˆï¼‰ã€‚"""
    if df is None or df.empty:
        return None

    # ç»˜å›¾æœ€å¤šä½¿ç”¨ 20 è¡Œï¼ˆä¸ç»“æœé™åˆ¶ä¸€è‡´ï¼‰
    d = df.copy().head(20)

    # å°è¯•è¯†åˆ«æ—¶é—´åˆ—
    datetime_cols: List[str] = []
    for c in d.columns:
        if pd.api.types.is_datetime64_any_dtype(d[c]):
            datetime_cols.append(c)
            continue
        if pd.api.types.is_object_dtype(d[c]):
            # å°è¯• parse
            parsed = pd.to_datetime(d[c], errors="coerce", utc=False)
            if parsed.notna().mean() > 0.8:
                d[c] = parsed
                datetime_cols.append(c)

    numeric_cols = [c for c in d.columns if pd.api.types.is_numeric_dtype(d[c])]
    cat_cols = [c for c in d.columns if c not in numeric_cols and c not in datetime_cols]

    # æ—¶é—´ + æ•°å€¼ => æŠ˜çº¿
    if datetime_cols and numeric_cols:
        x = datetime_cols[0]
        y = numeric_cols[0]
        dd = d[[x, y]].dropna().sort_values(x)
        return {
            "tooltip": {"trigger": "axis"},
            "xAxis": {"type": "category", "data": dd[x].dt.strftime("%Y-%m-%d %H:%M:%S").tolist()},
            "yAxis": {"type": "value"},
            "series": [{"type": "line", "data": dd[y].tolist(), "smooth": True}],
        }

    # åˆ†ç±» + æ•°å€¼ => æ¡å½¢
    if cat_cols and numeric_cols:
        x = cat_cols[0]
        y = numeric_cols[0]
        dd = d[[x, y]].dropna()
        # å–å‰ 20 ç±»
        dd = dd.head(20)
        return {
            "tooltip": {"trigger": "axis"},
            "xAxis": {"type": "category", "data": dd[x].astype(str).tolist(), "axisLabel": {"rotate": 30}},
            "yAxis": {"type": "value"},
            "series": [{"type": "bar", "data": dd[y].tolist()}],
        }

    # ä¸¤ä¸ªæ•°å€¼ => æ•£ç‚¹
    if len(numeric_cols) >= 2:
        x, y = numeric_cols[0], numeric_cols[1]
        dd = d[[x, y]].dropna().head(500)
        return {
            "tooltip": {"trigger": "item"},
            "xAxis": {"type": "value", "name": x},
            "yAxis": {"type": "value", "name": y},
            "series": [{"type": "scatter", "data": dd.values.tolist()}],
        }

    return None

# é¡µé¢é…ç½®
st.set_page_config(
    page_title="SQL Agent - æ™ºèƒ½æŸ¥è¯¢åŠ©æ‰‹",
    page_icon="ğŸ¤–",
    layout="wide"
)

# è‡ªå®šä¹‰æ ·å¼ï¼šå‡å°‘é—ªçƒï¼Œå¢å¼ºè§†è§‰åé¦ˆ
st.markdown("""
<style>
    /* è¿›åº¦æç¤ºåŠ¨ç”» */
    @keyframes pulse {
        0%, 100% { opacity: 1; }
        50% { opacity: 0.7; }
    }
    .stStatus { transition: all 0.3s ease; }
    
    /* æ•°æ®è¡¨æ ¼è¿‡æ¸¡ */
    .stDataFrame { 
        animation: fadeIn 0.3s ease-in-out;
    }
    @keyframes fadeIn {
        from { opacity: 0; transform: translateY(10px); }
        to { opacity: 1; transform: translateY(0); }
    }
    
    /* å›¾è¡¨å®¹å™¨ */
    iframe[title*="streamlit_echarts"] {
        animation: slideUp 0.4s ease-out;
    }
    @keyframes slideUp {
        from { opacity: 0; transform: translateY(20px); }
        to { opacity: 1; transform: translateY(0); }
    }
    
    /* èŠå¤©æ¶ˆæ¯ä¼˜åŒ– */
    .stChatMessage {
        transition: all 0.2s ease;
    }
    
    /* ä¸‹è½½æŒ‰é’®æ‚¬åœæ•ˆæœ */
    .stDownloadButton > button:hover {
        transform: translateY(-2px);
        box-shadow: 0 4px 12px rgba(0,0,0,0.15);
    }
    .stDownloadButton > button {
        transition: all 0.2s ease;
    }
</style>
""", unsafe_allow_html=True)

# ä½¿ç”¨ @st.cache_resource ç¼“å­˜ Agent å¯¹è±¡ï¼ˆè·¨ä¼šè¯å…±äº«ï¼Œåˆ·æ–°é¡µé¢ä¸é‡æ–°åˆå§‹åŒ–ï¼‰
@st.cache_resource
def get_sql_agent(db_name: str = None):
    """
    è·å–ç¼“å­˜çš„ SQL Agent å¯¹è±¡
    ä½¿ç”¨ @st.cache_resource ä½¿è¿æ¥åœ¨æ‰€æœ‰ç”¨æˆ·ä¼šè¯é—´å…±äº«
    åˆ·æ–°é¡µé¢æˆ–æ–°æ ‡ç­¾é¡µéƒ½ä¸ä¼šé‡æ–°åˆå§‹åŒ–
    """
    return SQLAgent(db_name=db_name)

# åˆå§‹åŒ– session state
if "messages" not in st.session_state:
    st.session_state.messages = []

if "db_name" not in st.session_state:
    st.session_state.db_name = Config.DB_NAME

# ç”¨äºæ›´é¡ºæ»‘çš„â€œè¿è¡Œä¸­ç¦ç”¨è¾“å…¥æ¡†â€ä½“éªŒï¼ˆä¸¤æ®µå¼ rerunï¼‰
if "pending_prompt" not in st.session_state:
    st.session_state.pending_prompt = None
if "is_running" not in st.session_state:
    st.session_state.is_running = False

# è·å–ç¼“å­˜çš„ Agentï¼ˆé¦–æ¬¡åŠ è½½ä¼šæ˜¾ç¤ºåŠ è½½æç¤ºï¼‰
try:
    with st.spinner("æ­£åœ¨è¿æ¥äº‘ç«¯æ•°æ®åº“å¹¶åˆå§‹åŒ–Agent..."):
        agent = get_sql_agent(st.session_state.db_name)
except Exception as e:
    st.error(f"åˆå§‹åŒ– Agent å¤±è´¥: {e}")
    st.stop()

# ä¾§è¾¹æ é…ç½®
with st.sidebar:
    st.title("âš™ï¸ é…ç½®")
    
    # æ•°æ®åº“é€‰æ‹©ï¼ˆä½¿ç”¨ç¼“å­˜é¿å…é‡å¤æŸ¥è¯¢ï¼‰
    @st.cache_data(ttl=300)  # ç¼“å­˜5åˆ†é’Ÿ
    def get_databases():
        return Config.get_available_databases()
    
    try:
        databases = get_databases()
        selected_db = st.selectbox(
            "é€‰æ‹©æ•°æ®åº“",
            databases,
            index=databases.index(st.session_state.db_name) if st.session_state.db_name in databases else 0
        )
        
        if selected_db != st.session_state.db_name:
            with st.spinner(f"åˆ‡æ¢åˆ°æ•°æ®åº“ {selected_db}..."):
                # æ¸…é™¤ç¼“å­˜ï¼Œé‡æ–°è·å–æ–°æ•°æ®åº“çš„ Agent
                get_sql_agent.clear()
                st.session_state.db_name = selected_db
                st.rerun()  # é‡æ–°è¿è¡Œä»¥ä½¿ç”¨æ–°çš„æ•°æ®åº“
    except Exception as e:
        st.error(f"è·å–æ•°æ®åº“åˆ—è¡¨å¤±è´¥: {e}")
    
    st.divider()
    
    # æ˜¾ç¤ºå½“å‰æ•°æ®åº“ä¿¡æ¯
    st.subheader("ğŸ“Š æ•°æ®åº“ä¿¡æ¯")
    if st.button("æŸ¥çœ‹ Schema"):
        schema_info = agent.get_schema_info()
        st.write(f"**æ•°æ®åº“**: {schema_info['database']}")
        st.write(f"**è¡¨åˆ—è¡¨**: {', '.join(schema_info['tables'])}")
        with st.expander("è¯¦ç»†ç»“æ„"):
            st.code(schema_info['table_info'], language="sql")
    
    st.divider()
    
    # æ¸…ç©ºå¯¹è¯
    if st.button("ğŸ—‘ï¸ æ¸…ç©ºå¯¹è¯"):
        st.session_state.messages = []
        st.rerun()

# ä¸»ç•Œé¢
st.title("ğŸ¤– SQL Agent - æ™ºèƒ½ MySQL æŸ¥è¯¢åŠ©æ‰‹")
st.caption(f"å½“å‰æ•°æ®åº“: **{st.session_state.db_name}**")

# æ˜¾ç¤ºå¯¹è¯å†å²ï¼ˆä½¿ç”¨ç¼“å­˜çš„æ•°æ®ï¼Œé¿å…é‡å¤æ¸²æŸ“ï¼‰
for msg_idx, message in enumerate(st.session_state.messages):
    with st.chat_message(message["role"]):
        # å¦‚æœæ˜¯åŠ©æ‰‹æ¶ˆæ¯ä¸”æœ‰SQLï¼Œå…ˆæ˜¾ç¤ºSQL
        if message["role"] == "assistant" and "sql" in message:
            with st.expander("ğŸ“ æŸ¥çœ‹ç”Ÿæˆçš„ SQL è¯­å¥", expanded=False):
                st.code(message["sql"], language="sql")

        # å¦‚æœå†å²æ¶ˆæ¯é‡Œæœ‰ last_sqlï¼Œåˆ™é‡ç»˜"è¡¨æ ¼ + ä¸‹è½½ + å›¾è¡¨"
        if message["role"] == "assistant" and message.get("last_sql"):
            try:
                # å†å²é‡ç»˜ä¹Ÿèµ°ç»Ÿä¸€ LIMIT è§„åˆ™ï¼ˆâ‰¤20ï¼‰
                eff = int(message.get("effective_limit") or 20)
                eff = max(1, min(eff, MAX_HARD_LIMIT))
                limited_sql = sanitize_sql_query(message["last_sql"], default_limit=eff, hard_limit=MAX_HARD_LIMIT)
                df_hist = get_df_for_sql(st.session_state.db_name, limited_sql)
                effective_limit = int(message.get("effective_limit") or 20)
                PREVIEW_ROWS = min(effective_limit, 20)
                preview_df = df_hist.head(PREVIEW_ROWS)
                
                # æ˜¾ç¤ºå…¨é‡è¡Œæ•°ï¼ˆä¼˜å…ˆä½¿ç”¨ç¼“å­˜çš„ full_countï¼‰
                full_count = message.get("full_count")
                if full_count is not None and full_count <= PREVIEW_ROWS:
                    st.markdown(f"**ğŸ“„ æŸ¥è¯¢ç»“æœï¼ˆå…± {full_count} è¡Œï¼Œå·²å…¨éƒ¨å±•ç¤ºï¼‰**")
                elif full_count is not None:
                    st.markdown(f"**ğŸ“„ æŸ¥è¯¢ç»“æœï¼ˆå‰ {PREVIEW_ROWS} è¡Œ / å…± {full_count} è¡Œï¼‰**")
                elif len(df_hist) <= PREVIEW_ROWS:
                    st.markdown(f"**ğŸ“„ æŸ¥è¯¢ç»“æœï¼ˆå…± {len(df_hist)} è¡Œï¼Œå·²å…¨éƒ¨å±•ç¤ºï¼‰**")
                else:
                    st.markdown(f"**ğŸ“„ æŸ¥è¯¢ç»“æœï¼ˆå‰ {PREVIEW_ROWS} è¡Œ / å…± {len(df_hist)} è¡Œï¼‰**")
                st.dataframe(preview_df, use_container_width=True)

                # å…¨é‡ä¸‹è½½ï¼ˆExcelï¼‰â€” éœ€è¦å”¯ä¸€ keyï¼Œé¿å… rerun åç»„ä»¶çŠ¶æ€é”™ä¹±
                excel_bytes = build_excel_bytes(df_hist)
                filename = f"query_result_{datetime.now().strftime('%Y%m%d_%H%M%S')}.xlsx"
                dl_key = f"download-{stable_key_for_sql(st.session_state.db_name, message['last_sql'])}"
                st.download_button(
                    label="â¬‡ï¸ ä¸‹è½½å…¨é‡ç»“æœï¼ˆExcelï¼‰",
                    data=excel_bytes,
                    file_name=filename,
                    mime="application/vnd.openxmlformats-officedocument.spreadsheetml.sheet",
                    key=dl_key,
                )

                # å›¾è¡¨æ¸²æŸ“ï¼šä¼˜å…ˆä½¿ç”¨å·²ç¼“å­˜çš„ echarts_optionï¼Œé¿å…é‡å¤è°ƒç”¨ LLM
                if HAS_ECHARTS:
                    cached_viz = message.get("echarts_viz")
                    if cached_viz is not None:
                        # ç›´æ¥ä½¿ç”¨å·²å­˜å‚¨çš„é…ç½®
                        if cached_viz.get("show") and isinstance(cached_viz.get("option"), dict):
                            st.markdown("**ğŸ“Š å¯è§†åŒ–ï¼ˆEChartsï¼‰**")
                            st_echarts(cached_viz["option"], height="420px", key=f"chart-{dl_key}")
                        elif cached_viz.get("reason"):
                            st.caption(f"ğŸ“Š ä¸å±•ç¤ºå›¾è¡¨ï¼š{cached_viz.get('reason', 'æ•°æ®ä¸é€‚åˆ')}")
                    else:
                        # å…œåº•ï¼šä½¿ç”¨ç¼“å­˜å‡½æ•°ï¼ˆä»ç„¶å¯èƒ½è°ƒç”¨ LLMï¼Œä½†æœ‰ TTL ç¼“å­˜ï¼‰
                        try:
                            df_info = build_df_info_for_viz(df_hist, max_rows=20)
                            cache_key = f"hist-{dl_key}"
                            viz = get_cached_echarts_option(
                                cache_key=cache_key,
                                question="(å†å²æ¶ˆæ¯é‡ç»˜)",
                                sql=message.get("last_sql", ""),
                                df_info_json=json.dumps(df_info, ensure_ascii=False, default=str),
                                _agent=agent,
                            )
                            if viz.get("show") and isinstance(viz.get("option"), dict):
                                st.markdown("**ğŸ“Š å¯è§†åŒ–ï¼ˆEChartsï¼‰**")
                                st_echarts(viz["option"], height="420px", key=f"chart-{dl_key}")
                            else:
                                st.caption(f"ğŸ“Š ä¸å±•ç¤ºå›¾è¡¨ï¼š{viz.get('reason', 'æ•°æ®ä¸é€‚åˆ')}")
                        except Exception as e:
                            st.caption(f"ğŸ“Š å›¾è¡¨ç”Ÿæˆå¤±è´¥ï¼š{e}")
            except Exception as e:
                st.caption(f"âš ï¸ æŸ¥è¯¢ç»“æœå±•ç¤ºå¤±è´¥ï¼š{e}")
        
        # æ˜¾ç¤ºæ¶ˆæ¯å†…å®¹ï¼ˆå…è®¸åŠ©æ‰‹æ¶ˆæ¯ content ä¸ºç©ºï¼šåªå±•ç¤ºè¡¨æ ¼/ä¸‹è½½ç­‰ç»„ä»¶ï¼Œä¸é¢å¤–è¾“å‡º"æŸ¥è¯¢å®Œæˆâ€¦"æ–‡æ¡ˆï¼‰
        content = message.get("content", "")
        if isinstance(content, str) and content.strip():
            st.markdown(content)

# è¾“å…¥æ¡†
# è¾“å…¥æ¡†ï¼ˆè¿è¡Œä¸­ç¦ç”¨ï¼Œå¹¶æç¤ºâ€œæ­£åœ¨è¿è¡Œâ€ï¼‰
prompt_input = st.chat_input(
    "è¯·è¾“å…¥æ‚¨çš„é—®é¢˜..." if not st.session_state.is_running else "æ­£åœ¨æŸ¥è¯¢ä¸­ï¼Œè¯·ç¨å€™â€¦",
    disabled=bool(st.session_state.is_running),
)

# ç¬¬ä¸€æ­¥ï¼šç”¨æˆ·æäº¤åå…ˆç¼“å­˜ prompt å¹¶ rerunï¼Œä½¿è¾“å…¥æ¡†ç«‹å³è¿›å…¥â€œè¿è¡Œä¸­â€çŠ¶æ€ï¼ˆæ›´é¡ºæ»‘ï¼‰
if prompt_input:
    st.session_state.pending_prompt = prompt_input
    st.session_state.is_running = True
    st.rerun()

# ç¬¬äºŒæ­¥ï¼šå¦‚æœæœ‰å¾…å¤„ç† prompt ä¸” is_running=Trueï¼Œå°±æ‰§è¡ŒæŸ¥è¯¢
if st.session_state.pending_prompt and st.session_state.is_running:
    prompt = st.session_state.pending_prompt

    # æ·»åŠ ç”¨æˆ·æ¶ˆæ¯ï¼ˆåªæ·»åŠ ä¸€æ¬¡ï¼‰
    st.session_state.messages.append({"role": "user", "content": prompt})
    with st.chat_message("user"):
        st.markdown(prompt)

    with st.chat_message("assistant"):
        # å·¥å…·è°ƒç”¨æµç¨‹å±•ç¤ºï¼ˆé»˜è®¤æŠ˜å ï¼Œç”¨æˆ·ç‚¹å‡»å¯å±•å¼€æŸ¥çœ‹è¯¦æƒ…ï¼‰
        status_box = st.status("æ­£åœ¨æ‰§è¡ŒæŸ¥è¯¢...", expanded=False, state="running")
        live_handler = StreamlitStatusTraceHandler(status_box)

        tool_result = agent.run_tools(prompt, callbacks=[live_handler])

        if tool_result.get("success"):
            status_box.update(label="æŸ¥è¯¢æ‰§è¡ŒæˆåŠŸï¼ˆç‚¹å‡»å±•å¼€è¯¦æƒ…ï¼‰", state="complete", expanded=False)
        else:
            status_box.update(label="æŸ¥è¯¢æ‰§è¡Œå¤±è´¥ï¼ˆç‚¹å‡»æŸ¥çœ‹è¯¦æƒ…ï¼‰", state="error", expanded=False)

        df = None
        full_count = None
        echarts_viz = None  # ç”¨äºç¼“å­˜åˆ°æ¶ˆæ¯

        if tool_result.get("success"):
            if tool_result.get("sql"):
                with st.expander("ğŸ“ æŸ¥çœ‹ç”Ÿæˆçš„ SQL è¯­å¥", expanded=False):
                    st.code(tool_result["sql"], language="sql")

            last_sql = tool_result.get("last_sql", "") or ""
            if last_sql:
                try:
                    eff = int(tool_result.get("effective_limit") or 20)
                    eff = max(1, min(eff, MAX_HARD_LIMIT))
                    limited_sql = sanitize_sql_query(last_sql, default_limit=eff, hard_limit=MAX_HARD_LIMIT)

                    engine = get_sqlalchemy_engine(st.session_state.db_name)
                    df = execute_sql_to_df(limited_sql, engine)

                    # è®¡ç®—"å…¨é‡è¡Œæ•°"ï¼šå¯¹å»æ‰ LIMIT çš„ SQL åš COUNT(*)ï¼ˆå¤±è´¥åˆ™å›é€€ä¸º len(df)ï¼‰
                    try:
                        sql_no_limit = strip_trailing_limit(last_sql)
                        count_sql = f"SELECT COUNT(*) FROM ({sql_no_limit}) AS t"
                        full_count = int(execute_scalar(count_sql, engine))
                    except Exception:
                        full_count = int(len(df)) if isinstance(df, pd.DataFrame) else None

                    PREVIEW_ROWS = min(eff, 20)
                    preview_df = df.head(PREVIEW_ROWS)
                    if full_count is not None and full_count <= PREVIEW_ROWS:
                        st.markdown(f"**ğŸ“„ æŸ¥è¯¢ç»“æœï¼ˆå…± {full_count} è¡Œï¼Œå·²å…¨éƒ¨å±•ç¤ºï¼‰**")
                    elif full_count is not None:
                        st.markdown(f"**ğŸ“„ æŸ¥è¯¢ç»“æœï¼ˆå‰ {PREVIEW_ROWS} è¡Œ / å…± {full_count} è¡Œï¼‰**")
                    else:
                        st.markdown(f"**ğŸ“„ æŸ¥è¯¢ç»“æœï¼ˆå‰ {PREVIEW_ROWS} è¡Œï¼‰**")
                    st.dataframe(preview_df, use_container_width=True)

                    # å…¨é‡ä¸‹è½½
                    excel_bytes = build_excel_bytes(df)
                    filename = f"query_result_{datetime.now().strftime('%Y%m%d_%H%M%S')}.xlsx"
                    st.download_button(
                        label="â¬‡ï¸ ä¸‹è½½å…¨é‡ç»“æœï¼ˆExcelï¼‰",
                        data=excel_bytes,
                        file_name=filename,
                        mime="application/vnd.openxmlformats-officedocument.spreadsheetml.sheet",
                        key=f"download-live-{stable_key_for_sql(st.session_state.db_name, limited_sql)}",
                    )

                    # å¯è§†åŒ–ç”Ÿæˆ
                    if HAS_ECHARTS:
                        chart_placeholder = st.empty()
                        chart_placeholder.info("æ­£åœ¨ç”Ÿæˆå¯è§†åŒ–å›¾è¡¨...")
                        
                        try:
                            df_info = build_df_info_for_viz(df, max_rows=20)
                            viz = agent.generate_echarts_option(
                                question=prompt,
                                sql=tool_result.get("sql", ""),
                                df_info=df_info,
                            )
                            echarts_viz = viz  # ç¼“å­˜åˆ°æ¶ˆæ¯
                            
                            chart_placeholder.empty()  # æ¸…é™¤ loading æç¤º
                            if viz.get("show") and isinstance(viz.get("option"), dict):
                                st.markdown("**ğŸ“Š å¯è§†åŒ–ï¼ˆEChartsï¼‰**")
                                st_echarts(viz["option"], height="420px", key=f"chart-live-{stable_key_for_sql(st.session_state.db_name, limited_sql)}")
                            else:
                                st.caption(f"ğŸ“Š ä¸å±•ç¤ºå›¾è¡¨ï¼š{viz.get('reason', 'æ•°æ®ä¸é€‚åˆ')}")
                        except Exception as e:
                            chart_placeholder.empty()
                            st.caption(f"ğŸ“Š å›¾è¡¨ç”Ÿæˆå¤±è´¥ï¼š{e}")
                            echarts_viz = {"show": False, "reason": str(e)}
                    else:
                        st.caption("ğŸ“Š æœªå®‰è£… `streamlit-echarts`ï¼Œæš‚ä¸å±•ç¤ºå›¾è¡¨ã€‚")
                except Exception as e:
                    st.caption(f"âš ï¸ æŸ¥è¯¢ç»“æœå±•ç¤ºå¤±è´¥ï¼š{e}")
            else:
                st.caption("âš ï¸ æœªæ•è·åˆ°å¯ç”¨äºå±•ç¤ºçš„æ•°æ®æŸ¥è¯¢ SQLï¼ˆlast_sql ä¸ºç©ºï¼‰ã€‚")

            # ä¿å­˜åˆ°æ¶ˆæ¯å†å²ï¼šä¿å­˜ last_sql + effective_limit + full_count + echarts_viz
            msg = {"role": "assistant", "content": ""}
            if tool_result.get("sql"):
                msg["sql"] = tool_result["sql"]
            if tool_result.get("last_sql"):
                msg["last_sql"] = tool_result["last_sql"]
            msg["effective_limit"] = int(tool_result.get("effective_limit") or 20)
            if full_count is not None:
                msg["full_count"] = int(full_count)
            if echarts_viz is not None:
                msg["echarts_viz"] = echarts_viz  # ç¼“å­˜å›¾è¡¨é…ç½®ï¼Œå†å²æ¸²æŸ“æ—¶ç›´æ¥ä½¿ç”¨
            st.session_state.messages.append(msg)
        else:
            error_msg = f"âŒ æŸ¥è¯¢å¤±è´¥: {tool_result.get('error', 'æœªçŸ¥é”™è¯¯')}"
            st.error(error_msg)
            st.session_state.messages.append({"role": "assistant", "content": error_msg})

    # æ¸…ç†è¿è¡Œæ ‡è®°å¹¶ rerunï¼Œæ¢å¤è¾“å…¥æ¡†
    st.session_state.pending_prompt = None
    st.session_state.is_running = False
    st.rerun()

# ï¼ˆå·²ç§»é™¤ï¼‰ç¤ºä¾‹é—®é¢˜ã€ç³»ç»Ÿä¿¡æ¯ï¼šä¿æŒèŠå¤©ç•Œé¢ç®€æ´
