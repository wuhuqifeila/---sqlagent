"""
åŸºäº Streamlit çš„ SQL Agent Web ç•Œé¢
æä¾›èŠå¤©å¼äº¤äº’å’Œç»“æœå¯è§†åŒ–
"""
import streamlit as st
import sys
import os
import json
from io import BytesIO
from datetime import datetime
from typing import Any, Dict, List, Optional
from langchain_core.callbacks import BaseCallbackHandler
import time
import pandas as pd
from sqlalchemy import create_engine
import hashlib
import re
import asyncio

# Add missing import for HumanMessage
from langchain_core.messages import HumanMessage

# æ·»åŠ é¡¹ç›®æ ¹ç›®å½•åˆ° Python è·¯å¾„
sys.path.insert(0, os.path.dirname(os.path.dirname(os.path.abspath(__file__))))

from sqlagent import SQLAgent, Config
from sqlagent.agent import LIMIT_ALL
from sqlagent.security import sanitize_sql_query, MAX_HARD_LIMIT
from sqlagent.code_sandbox import execute_analysis_code

# EChartsï¼ˆå¯é€‰ä¾èµ–ï¼Œæœªå®‰è£…æ—¶è‡ªåŠ¨é™çº§ä¸æ˜¾ç¤ºå›¾è¡¨ï¼‰
try:
    from streamlit_echarts import st_echarts  # type: ignore
    HAS_ECHARTS = True
except Exception:
    HAS_ECHARTS = False


class StreamlitStatusTraceHandler(BaseCallbackHandler):
    """æŠŠå·¥å…·è°ƒç”¨è¿‡ç¨‹å®æ—¶å†™åˆ° Streamlit çš„ st.statusï¼Œå±•ç¤ºå®Œæ•´æ‰§è¡Œæµç¨‹ã€‚"""

    def __init__(self, status_box):
        self.status_box = status_box
        self.step_no = 0
        self._current_tool: Optional[str] = None

    @staticmethod
    def _norm(v: Any) -> str:
        if v is None:
            return ""
        if isinstance(v, str):
            return v.strip()
        if isinstance(v, dict):
            # å¸¸è§ï¼š{"query": "..."} / {"tool_input": "..."}
            if "query" in v and isinstance(v["query"], str):
                return v["query"].strip()
            if "tool_input" in v and isinstance(v["tool_input"], str):
                return v["tool_input"].strip()
            return str(v)
        return str(v).strip()

    def on_tool_start(self, serialized: Dict[str, Any], input_str: Any = None, **kwargs) -> None:
        tool_name = (serialized or {}).get("name") or kwargs.get("name") or ""
        normalized_input = self._norm(input_str if input_str is not None else kwargs.get("input"))

        self.step_no += 1
        self._current_tool = tool_name
        
        # æ˜¾ç¤ºå·¥å…·è°ƒç”¨ä¿¡æ¯
        self.status_box.write(f"**{self.step_no}. è°ƒç”¨å·¥å…·ï¼š`{tool_name}`**")
        if normalized_input:
            if tool_name == "sql_db_query":
                self.status_box.write("è¾“å…¥ï¼ˆSQLï¼‰ï¼š")
                self.status_box.code(normalized_input, language="sql")
            else:
                self.status_box.write("è¾“å…¥ï¼š")
                self.status_box.code(normalized_input)

    def on_tool_end(self, output: Any, **kwargs) -> None:
        normalized_output = self._norm(output)
        if normalized_output:
            self.status_box.write("è¾“å‡ºï¼š")
            self.status_box.code(normalized_output)

    def on_tool_error(self, error: Exception, **kwargs) -> None:
        self.status_box.write(f"âŒ å·¥å…·æ‰§è¡Œå‡ºé”™ï¼š{error}")


class StreamlitAnswerStreamHandler(BaseCallbackHandler):
    """åªç”¨äºâ€œæœ€ç»ˆå›ç­”â€çš„ token æµå¼å±•ç¤ºã€‚"""

    def __init__(self, placeholder: "st.delta_generator.DeltaGenerator"):
        self.placeholder = placeholder
        self._buf: List[str] = []
        self._last_flush = 0.0

    def on_llm_new_token(self, token: str, **kwargs) -> None:
        self._buf.append(token)
        now = time.monotonic()
        # è½»å¾®èŠ‚æµï¼Œé¿å…æ¯ä¸ª token éƒ½è§¦å‘ UI é‡ç»˜
        if now - self._last_flush >= 0.05:
            self.placeholder.markdown("".join(self._buf))
            self._last_flush = now

    def flush(self) -> str:
        text = "".join(self._buf)
        self.placeholder.markdown(text)
        return text


@st.cache_resource
def get_sqlalchemy_engine(db_name: str):
    """å¤ç”¨ SQLAlchemy Engineï¼ˆé¿å…æ¯æ¬¡éƒ½æ–°å»ºè¿æ¥æ± ï¼‰ã€‚"""
    uri = Config.get_db_uri(db_name)
    engine_args = {
        "pool_pre_ping": True,
        "pool_size": 5,
        "max_overflow": 10,
        "pool_recycle": 3600,
        "connect_args": {"connect_timeout": 10},
    }
    return create_engine(uri, **engine_args)




def build_excel_bytes(df: pd.DataFrame) -> bytes:
    buf = BytesIO()
    with pd.ExcelWriter(buf, engine="openpyxl") as writer:
        df.to_excel(writer, index=False, sheet_name="result")
    return buf.getvalue()

def df_preview_text(df: pd.DataFrame, n: int = 20) -> str:
    """ç»™æ¨¡å‹ç”¨çš„æ ·ä¾‹æ–‡æœ¬ï¼šæœ€å¤š n è¡Œï¼Œé¿å…ä¸Šä¸‹æ–‡çˆ†ç‚¸ã€‚"""
    if df is None or df.empty:
        return "(ç©ºç»“æœ)"
    d = df.head(n).copy()
    # å…¨éƒ¨è½¬æˆå­—ç¬¦ä¸²ï¼Œé¿å… datetime/decimal ç­‰åœ¨ markdown é‡Œè¿‡é•¿
    for c in d.columns:
        d[c] = d[c].astype(str)
    try:
        return d.to_markdown(index=False)
    except Exception:
        # å…œåº•ï¼šCSV
        return d.to_csv(index=False)

@st.cache_data(ttl=300, show_spinner=False)
def get_df_for_sql(db_name: str, sql: str) -> pd.DataFrame:
    """ä¸ºå†å²æ¶ˆæ¯é‡ç»˜/ä¸‹è½½é‡è·‘æä¾› DataFrameï¼ˆå¸¦ç¼“å­˜ï¼Œé¿å…é¢‘ç¹æ‰“åº“ï¼‰ã€‚"""
    engine = get_sqlalchemy_engine(db_name)
    return execute_sql_to_df(sql, engine)

def stable_key_for_sql(db_name: str, sql: str) -> str:
    raw = (db_name + "\n" + (sql or "")).encode("utf-8", errors="ignore")
    return hashlib.md5(raw).hexdigest()


# ç¼“å­˜å›¾è¡¨é…ç½®ï¼Œé¿å…å†å²æ¶ˆæ¯é‡å¤è°ƒç”¨ LLM
@st.cache_data(ttl=600, show_spinner=False)
def get_cached_echarts_option(cache_key: str, question: str, sql: str, df_info_json: str, _agent) -> Dict[str, Any]:
    """ç¼“å­˜ ECharts é…ç½®ç”Ÿæˆç»“æœï¼Œé¿å…å†å²æ¶ˆæ¯æ¯æ¬¡ rerun éƒ½é‡æ–°è°ƒç”¨ LLMã€‚"""
    import json
    df_info = json.loads(df_info_json) if df_info_json else {}
    return _agent.generate_echarts_option(question=question, sql=sql, df_info=df_info)

def build_df_info_for_viz(df: pd.DataFrame, max_rows: int = 20) -> Dict[str, Any]:
    """ç»™ LLM ç”¨çš„å¯è§†åŒ–ä¸Šä¸‹æ–‡ï¼šé¿å…å¡å…¨é‡ï¼Œæä¾›åˆ—ç±»å‹/åŸºæ•°/æ ·ä¾‹/ç®€å•ç»Ÿè®¡ã€‚"""
    if df is None or df.empty:
        return {"row_count": 0, "columns": [], "sample_rows": []}

    d = df.copy().head(max_rows)

    cols_info: List[Dict[str, Any]] = []
    for c in d.columns:
        s = d[c]
        # åŸºæœ¬ç±»å‹
        if pd.api.types.is_numeric_dtype(s):
            col_type = "number"
        elif pd.api.types.is_datetime64_any_dtype(s):
            col_type = "datetime"
        else:
            col_type = "string"

        nunique = int(s.astype(str).nunique(dropna=True))
        cols_info.append(
            {
                "name": str(c),
                "type": col_type,
                "nunique": nunique,
            }
        )

    # æ ·ä¾‹è¡Œï¼šè½¬æˆçº¯ Python ç±»å‹ï¼Œé¿å… datetime/decimal åºåˆ—åŒ–é—®é¢˜
    sample_rows = d.astype(str).to_dict(orient="records")

    # æ•°å€¼åˆ—ç®€å•ç»Ÿè®¡
    num_cols = [c for c in d.columns if pd.api.types.is_numeric_dtype(d[c])]
    numeric_summary: Dict[str, Any] = {}
    for c in num_cols[:5]:
        s = pd.to_numeric(d[c], errors="coerce")
        numeric_summary[str(c)] = {
            "min": float(s.min()) if s.notna().any() else None,
            "max": float(s.max()) if s.notna().any() else None,
            "mean": float(s.mean()) if s.notna().any() else None,
        }

    return {
        "row_count": int(len(df)),
        "columns": cols_info,
        "sample_rows": sample_rows,
        "numeric_summary": numeric_summary,
        "note": f"sample_rows ä»…ä¸ºå‰ {max_rows} è¡Œï¼Œç”¨äºé€‰å›¾ï¼›çœŸå®ç»“æœè¡Œæ•°è§ row_countã€‚",
    }

def execute_sql_to_df(sql: str, engine) -> pd.DataFrame:
    """
    ä½¿ç”¨ SQLAlchemy çš„ raw_connection è·å– DBAPI è¿æ¥ç›´æ¥æ‰§è¡Œ SQLï¼Œ
    è§„é¿æŸäº›é©±åŠ¨åœ¨åŒ…å« LIKE '%xx%' æ—¶æŠŠ % è¯¯å½“ä½œå ä½ç¬¦å¯¼è‡´çš„æ ¼å¼åŒ–é”™è¯¯ã€‚
    """
    q = (sql or "").strip().rstrip(";")
    if not q:
        return pd.DataFrame()

    conn = engine.raw_connection()
    try:
        cur = conn.cursor()
        cur.execute(q)  # ä¸ä¼ å‚æ•°ï¼Œç¡®ä¿ % ä½œä¸º SQL å­—é¢é‡ç”Ÿæ•ˆ
        rows = cur.fetchall()
        cols = [d[0] for d in (cur.description or [])]
        return pd.DataFrame(list(rows), columns=cols)
    finally:
        try:
            conn.close()
        except Exception:
            pass


def execute_scalar(sql: str, engine) -> Any:
    """æ‰§è¡Œè¿”å›å•ä¸ªå€¼çš„ SQLï¼ˆä¾‹å¦‚ COUNT(*)ï¼‰ã€‚"""
    q = (sql or "").strip().rstrip(";")
    if not q:
        return None
    conn = engine.raw_connection()
    try:
        cur = conn.cursor()
        cur.execute(q)
        row = cur.fetchone()
        return row[0] if row else None
    finally:
        try:
            conn.close()
        except Exception:
            pass


def strip_trailing_limit(sql: str) -> str:
    """
    å»é™¤æœ«å°¾ LIMIT å­å¥ï¼ˆä»…å¤„ç†æœ«å°¾çš„ LIMIT n / LIMIT offset,n / LIMIT n OFFSET offsetï¼‰ã€‚
    ç”¨äºè®¡ç®—â€œå…¨é‡è¡Œæ•°â€COUNT(*)ã€‚
    """
    s = (sql or "").strip().rstrip(";")
    # ç§»é™¤æœ«å°¾ LIMIT ...ï¼ˆå°½é‡ä¸å½±å“å­æŸ¥è¯¢å†… LIMITï¼‰
    s = re.sub(r"(?is)\s+limit\s+\d+\s*,\s*\d+\s*$", "", s)
    s = re.sub(r"(?is)\s+limit\s+\d+\s+offset\s+\d+\s*$", "", s)
    s = re.sub(r"(?is)\s+limit\s+\d+\s*$", "", s)
    return s.strip()


def auto_echarts_option(df: pd.DataFrame) -> Optional[Dict[str, Any]]:
    """æ ¹æ® df çš„åˆ—ç±»å‹è‡ªåŠ¨é€‰æ‹©ä¸€ä¸ªåˆé€‚çš„ ECharts optionï¼ˆç®€å•è§„åˆ™ç‰ˆï¼‰ã€‚"""
    if df is None or df.empty:
        return None

    # ç»˜å›¾æœ€å¤šä½¿ç”¨ 20 è¡Œï¼ˆä¸ç»“æœé™åˆ¶ä¸€è‡´ï¼‰
    d = df.copy().head(20)

    # å°è¯•è¯†åˆ«æ—¶é—´åˆ—
    datetime_cols: List[str] = []
    for c in d.columns:
        if pd.api.types.is_datetime64_any_dtype(d[c]):
            datetime_cols.append(c)
            continue
        if pd.api.types.is_object_dtype(d[c]):
            # å°è¯• parse
            parsed = pd.to_datetime(d[c], errors="coerce", utc=False)
            if parsed.notna().mean() > 0.8:
                d[c] = parsed
                datetime_cols.append(c)

    numeric_cols = [c for c in d.columns if pd.api.types.is_numeric_dtype(d[c])]
    cat_cols = [c for c in d.columns if c not in numeric_cols and c not in datetime_cols]

    # æ—¶é—´ + æ•°å€¼ => æŠ˜çº¿
    if datetime_cols and numeric_cols:
        x = datetime_cols[0]
        y = numeric_cols[0]
        dd = d[[x, y]].dropna().sort_values(x)
        return {
            "tooltip": {"trigger": "axis"},
            "xAxis": {"type": "category", "data": dd[x].dt.strftime("%Y-%m-%d %H:%M:%S").tolist()},
            "yAxis": {"type": "value"},
            "series": [{"type": "line", "data": dd[y].tolist(), "smooth": True}],
        }

    # åˆ†ç±» + æ•°å€¼ => æ¡å½¢
    if cat_cols and numeric_cols:
        x = cat_cols[0]
        y = numeric_cols[0]
        dd = d[[x, y]].dropna()
        # å–å‰ 20 ç±»
        dd = dd.head(20)
        return {
            "tooltip": {"trigger": "axis"},
            "xAxis": {"type": "category", "data": dd[x].astype(str).tolist(), "axisLabel": {"rotate": 30}},
            "yAxis": {"type": "value"},
            "series": [{"type": "bar", "data": dd[y].tolist()}],
        }

    # ä¸¤ä¸ªæ•°å€¼ => æ•£ç‚¹
    if len(numeric_cols) >= 2:
        x, y = numeric_cols[0], numeric_cols[1]
        dd = d[[x, y]].dropna().head(500)
        return {
            "tooltip": {"trigger": "item"},
            "xAxis": {"type": "value", "name": x},
            "yAxis": {"type": "value", "name": y},
            "series": [{"type": "scatter", "data": dd.values.tolist()}],
        }

    return None

# é¡µé¢é…ç½®
st.set_page_config(
    page_title="SQL Agent - æ™ºèƒ½æŸ¥è¯¢åŠ©æ‰‹",
    page_icon="ğŸ¤–",
    layout="wide"
)

# è‡ªå®šä¹‰æ ·å¼ï¼šå‡å°‘é—ªçƒï¼Œå¢å¼ºè§†è§‰åé¦ˆ
st.markdown("""
<style>
    /* è¿›åº¦æç¤ºåŠ¨ç”» */
    @keyframes pulse {
        0%, 100% { opacity: 1; }
        50% { opacity: 0.7; }
    }
    .stStatus { transition: all 0.3s ease; }
    
    /* æ•°æ®è¡¨æ ¼è¿‡æ¸¡ */
    .stDataFrame { 
        animation: fadeIn 0.3s ease-in-out;
    }
    @keyframes fadeIn {
        from { opacity: 0; transform: translateY(10px); }
        to { opacity: 1; transform: translateY(0); }
    }
    
    /* å›¾è¡¨å®¹å™¨ */
    iframe[title*="streamlit_echarts"] {
        animation: slideUp 0.4s ease-out;
    }
    @keyframes slideUp {
        from { opacity: 0; transform: translateY(20px); }
        to { opacity: 1; transform: translateY(0); }
    }
    
    /* èŠå¤©æ¶ˆæ¯ä¼˜åŒ– */
    .stChatMessage {
        transition: all 0.2s ease;
    }
    
    /* ä¸‹è½½æŒ‰é’®æ‚¬åœæ•ˆæœ */
    .stDownloadButton > button:hover {
        transform: translateY(-2px);
        box-shadow: 0 4px 12px rgba(0,0,0,0.15);
    }
    .stDownloadButton > button {
        transition: all 0.2s ease;
    }
</style>
""", unsafe_allow_html=True)

# ä½¿ç”¨ @st.cache_resource ç¼“å­˜ Agent å¯¹è±¡ï¼ˆè·¨ä¼šè¯å…±äº«ï¼Œåˆ·æ–°é¡µé¢ä¸é‡æ–°åˆå§‹åŒ–ï¼‰
@st.cache_resource
def get_sql_agent(db_name: str = None):
    """
    è·å–ç¼“å­˜çš„ SQL Agent å¯¹è±¡
    ä½¿ç”¨ @st.cache_resource ä½¿è¿æ¥åœ¨æ‰€æœ‰ç”¨æˆ·ä¼šè¯é—´å…±äº«
    åˆ·æ–°é¡µé¢æˆ–æ–°æ ‡ç­¾é¡µéƒ½ä¸ä¼šé‡æ–°åˆå§‹åŒ–
    """
    return SQLAgent(db_name=db_name)

# åˆå§‹åŒ– session state
if "messages" not in st.session_state:
    st.session_state.messages = []

if "db_name" not in st.session_state:
    st.session_state.db_name = Config.DB_NAME

# ç”¨äºæ›´é¡ºæ»‘çš„â€œè¿è¡Œä¸­ç¦ç”¨è¾“å…¥æ¡†â€ä½“éªŒï¼ˆä¸¤æ®µå¼ rerunï¼‰
if "pending_prompt" not in st.session_state:
    st.session_state.pending_prompt = None
if "is_running" not in st.session_state:
    st.session_state.is_running = False

# æ·»åŠ æ•°æ®åˆ†ææŠ¥å‘Šç›¸å…³çš„session state
if "analysis_reports" not in st.session_state:
    st.session_state.analysis_reports = {}

if "current_analysis_df" not in st.session_state:
    st.session_state.current_analysis_df = None

if "current_analysis_question" not in st.session_state:
    st.session_state.current_analysis_question = ""

# è·å–ç¼“å­˜çš„ Agentï¼ˆé¦–æ¬¡åŠ è½½ä¼šæ˜¾ç¤ºåŠ è½½æç¤ºï¼‰
try:
    with st.spinner("æ­£åœ¨è¿æ¥äº‘ç«¯æ•°æ®åº“å¹¶åˆå§‹åŒ–Agent..."):
        agent = get_sql_agent(st.session_state.db_name)
except Exception as e:
    st.error(f"åˆå§‹åŒ– Agent å¤±è´¥: {e}")
    st.stop()

# ä¾§è¾¹æ é…ç½®
with st.sidebar:
    st.title("âš™ï¸ é…ç½®")
    
    # æ•°æ®åº“é€‰æ‹©ï¼ˆä½¿ç”¨ç¼“å­˜é¿å…é‡å¤æŸ¥è¯¢ï¼‰
    @st.cache_data(ttl=300)  # ç¼“å­˜5åˆ†é’Ÿ
    def get_databases():
        return Config.get_available_databases()
    
    try:
        databases = get_databases()
        selected_db = st.selectbox(
            "é€‰æ‹©æ•°æ®åº“",
            databases,
            index=databases.index(st.session_state.db_name) if st.session_state.db_name in databases else 0
        )
        
        if selected_db != st.session_state.db_name:
            with st.spinner(f"åˆ‡æ¢åˆ°æ•°æ®åº“ {selected_db}..."):
                # æ¸…é™¤ç¼“å­˜ï¼Œé‡æ–°è·å–æ–°æ•°æ®åº“çš„ Agent
                get_sql_agent.clear()
                st.session_state.db_name = selected_db
                st.rerun()  # é‡æ–°è¿è¡Œä»¥ä½¿ç”¨æ–°çš„æ•°æ®åº“
    except Exception as e:
        st.error(f"è·å–æ•°æ®åº“åˆ—è¡¨å¤±è´¥: {e}")
    
    st.divider()
    
    # æ˜¾ç¤ºå½“å‰æ•°æ®åº“ä¿¡æ¯
    st.subheader("ğŸ“Š æ•°æ®åº“ä¿¡æ¯")
    if st.button("æŸ¥çœ‹ Schema"):
        schema_info = agent.get_schema_info()
        st.write(f"**æ•°æ®åº“**: {schema_info['database']}")
        st.write(f"**è¡¨åˆ—è¡¨**: {', '.join(schema_info['tables'])}")
        with st.expander("è¯¦ç»†ç»“æ„"):
            st.code(schema_info['table_info'], language="sql")
    
    st.divider()
    
    # æ¸…ç©ºå¯¹è¯
    if st.button("ğŸ—‘ï¸ æ¸…ç©ºå¯¹è¯"):
        st.session_state.messages = []
        st.rerun()

# ä¸»ç•Œé¢
st.title("ğŸ¤– SQL Agent - æ™ºèƒ½ MySQL æŸ¥è¯¢åŠ©æ‰‹")
st.caption(f"å½“å‰æ•°æ®åº“: **{st.session_state.db_name}**")

# æ˜¾ç¤ºå¯¹è¯å†å²ï¼ˆä½¿ç”¨ç¼“å­˜çš„æ•°æ®ï¼Œé¿å…é‡å¤æ¸²æŸ“ï¼‰
for msg_idx, message in enumerate(st.session_state.messages):
    with st.chat_message(message["role"]):
        # å¦‚æœæ˜¯åŠ©æ‰‹æ¶ˆæ¯ä¸”æœ‰SQLï¼Œå…ˆæ˜¾ç¤ºSQL
        if message["role"] == "assistant" and "sql" in message:
            with st.expander("ğŸ“ æŸ¥çœ‹ç”Ÿæˆçš„ SQL è¯­å¥", expanded=False):
                st.code(message["sql"], language="sql")

        # å¦‚æœå†å²æ¶ˆæ¯é‡Œæœ‰ last_sqlï¼Œåˆ™é‡ç»˜"è¡¨æ ¼ + ä¸‹è½½ + å›¾è¡¨"
        if message["role"] == "assistant" and message.get("last_sql"):
            try:
                # effective_limit æ˜¯ç”¨æˆ·æ„å›¾çš„æ•°é‡
                # - å…·ä½“æ•°å­—ï¼ˆå¦‚400ï¼‰ï¼šç”¨æˆ·è¯´"å‰400ä¸ª"
                # - LIMIT_ALL (999999)ï¼šç”¨æˆ·æƒ³è¦å…¨éƒ¨æ•°æ®
                eff = int(message.get("effective_limit") or 20)
                eff = max(1, eff)
                
                # è·å–ç¼“å­˜çš„ full_count
                full_count = message.get("full_count")
                
                # å¦‚æœç”¨æˆ·æƒ³è¦å…¨éƒ¨æ•°æ®ï¼ˆeff >= LIMIT_ALLï¼‰ï¼Œä¸‹è½½æ•°é‡ä½¿ç”¨ full_count
                if eff >= LIMIT_ALL and full_count is not None:
                    download_limit = full_count
                else:
                    download_limit = eff
                
                # é¢„è§ˆç”¨ SQLï¼ˆæœ€å¤š20è¡Œï¼‰
                preview_limit = min(download_limit, 20)
                preview_sql = sanitize_sql_query(message["last_sql"], default_limit=preview_limit, hard_limit=20)
                df_preview = get_df_for_sql(st.session_state.db_name, preview_sql)
                
                # æ˜¾ç¤ºå…¨é‡è¡Œæ•°
                if full_count is not None and full_count <= preview_limit:
                    st.markdown(f"**ğŸ“„ æŸ¥è¯¢ç»“æœï¼ˆå…± {full_count} è¡Œï¼Œå·²å…¨éƒ¨å±•ç¤ºï¼‰**")
                elif full_count is not None:
                    st.markdown(f"**ğŸ“„ æŸ¥è¯¢ç»“æœï¼ˆå‰ {len(df_preview)} è¡Œ / å…± {full_count} è¡Œï¼‰**")
                elif len(df_preview) <= preview_limit:
                    st.markdown(f"**ğŸ“„ æŸ¥è¯¢ç»“æœï¼ˆå…± {len(df_preview)} è¡Œï¼Œå·²å…¨éƒ¨å±•ç¤ºï¼‰**")
                else:
                    st.markdown(f"**ğŸ“„ æŸ¥è¯¢ç»“æœï¼ˆå‰ {len(df_preview)} è¡Œï¼‰**")
                st.dataframe(df_preview, use_container_width=True)

                # ä¸‹è½½ï¼šä½¿ç”¨ç”¨æˆ·æ„å›¾çš„æ•°é‡ï¼ˆæˆ–å…¨é‡ï¼‰
                download_sql = sanitize_sql_query(message["last_sql"], default_limit=download_limit, hard_limit=download_limit)
                df_download = get_df_for_sql(st.session_state.db_name, download_sql)
                excel_bytes = build_excel_bytes(df_download)
                filename = f"query_result_{datetime.now().strftime('%Y%m%d_%H%M%S')}.xlsx"
                dl_key = f"download-{stable_key_for_sql(st.session_state.db_name, message['last_sql'])}"
                download_rows = len(df_download)
                st.download_button(
                    label=f"â¬‡ï¸ ä¸‹è½½ç»“æœï¼ˆExcelï¼Œå…± {download_rows} è¡Œï¼‰",
                    data=excel_bytes,
                    file_name=filename,
                    mime="application/vnd.openxmlformats-officedocument.spreadsheetml.sheet",
                    key=dl_key,
                )

                # æ–°å¢ï¼šè‡ªå®šä¹‰åˆ†æè¦æ±‚è¾“å…¥æ¡†
                custom_analysis_req = st.text_input(
                    "ğŸ“Š è‡ªå®šä¹‰åˆ†æè¦æ±‚ï¼ˆå¯é€‰ï¼‰:",
                    key=f"custom-analysis-req-{dl_key}",
                    placeholder="ä¾‹å¦‚ï¼šé‡ç‚¹å…³æ³¨é”€å”®é¢è¶‹åŠ¿ã€æŒ‰åœ°åŒºåˆ†ç»„ç»Ÿè®¡ã€ç”Ÿæˆç›¸å…³æ€§çƒ­åŠ›å›¾ç­‰"
                )

                # æ–°å¢ï¼šç”Ÿæˆæ•°æ®åˆ†ææŠ¥å‘ŠæŒ‰é’®
                report_key = f"report-{dl_key}"
                if st.button("ğŸ“Š ç”Ÿæˆæ•°æ®åˆ†ææŠ¥å‘Š", key=f"generate-report-{dl_key}"):
                    try:
                        with st.spinner("æ­£åœ¨ç”Ÿæˆæ•°æ®åˆ†ææŠ¥å‘Š..."):
                            # ä¿å­˜å½“å‰åˆ†ææ‰€éœ€çš„æ•°æ®
                            st.session_state.current_analysis_df = df_download.copy()
                            st.session_state.current_analysis_question = message.get("question", "")
                            
                            # ç”ŸæˆExcelæ–‡ä»¶ç”¨äºæ²™ç®±æ‰§è¡Œ
                            excel_filename = f"temp_data_{datetime.now().strftime('%Y%m%d_%H%M%S')}.xlsx"
                            excel_path = f"/tmp/{excel_filename}"
                            df_download.to_excel(excel_path, index=False)
                            
                            # ç”ŸæˆPDFæŠ¥å‘Šæ–‡ä»¶è·¯å¾„
                            report_filename = f"analysis_report_{datetime.now().strftime('%Y%m%d_%H%M%S')}.pdf"
                            report_path = f"/tmp/{report_filename}"
                            
                            # æ„å»ºåˆ†ææç¤ºè¯
                            base_prompt = f"""
ä½ æ˜¯ä¸€åä¸“ä¸šçš„æ•°æ®ç§‘å­¦å®¶ã€‚è¯·åŸºäºç”¨æˆ·çš„é—®é¢˜å’Œæä¾›çš„DataFrameï¼ˆå˜é‡å: dfï¼‰ç”Ÿæˆå®Œæ•´çš„Pythonæ•°æ®åˆ†æä»£ç ã€‚

ç”¨æˆ·é—®é¢˜: {st.session_state.current_analysis_question}
"""
                            
                            if custom_analysis_req.strip():
                                base_prompt += f"\nç”¨æˆ·è‡ªå®šä¹‰åˆ†æè¦æ±‚: {custom_analysis_req.strip()}\n"
                            
                            analysis_prompt = base_prompt + f"""
è¦æ±‚ï¼š
1. è¿›è¡Œå…¨é¢çš„æ•°æ®åˆ†æï¼ŒåŒ…æ‹¬åŸºæœ¬ç»Ÿè®¡ã€ç›¸å…³æ€§åˆ†æã€åˆ†å¸ƒåˆ†æç­‰
2. ç”Ÿæˆé«˜è´¨é‡çš„å¯è§†åŒ–å›¾è¡¨ï¼ˆä½¿ç”¨matplotlib/seabornï¼‰ï¼Œ**æ‰€æœ‰å›¾è¡¨æ ‡é¢˜ã€æ ‡ç­¾ã€å›¾ä¾‹å¿…é¡»ä½¿ç”¨è‹±æ–‡**
3. å°†æ‰€æœ‰åˆ†æç»“æœæ•´åˆåˆ°ä¸€ä¸ªPDFæŠ¥å‘Šä¸­ï¼Œ**åŒ…å«è¯¦ç»†çš„ä¸­æ–‡æ–‡å­—æè¿°å’Œè§£é‡Š**
4. PDFæŠ¥å‘Šå¿…é¡»ä¿å­˜åˆ°è·¯å¾„: {report_path}
5. **ä¸­æ–‡æ–‡å­—æè¿°å†…å®¹åº”åŒ…æ‹¬**ï¼š
   - æ•°æ®æ¦‚è§ˆï¼ˆå½¢çŠ¶ã€åˆ—ä¿¡æ¯ã€æ•°æ®ç±»å‹ï¼‰
   - ç¼ºå¤±å€¼åˆ†æ
   - åŸºæœ¬ç»Ÿè®¡æ‘˜è¦
   - æ•°å€¼åˆ—çš„åˆ†å¸ƒç‰¹å¾åˆ†æ
   - åˆ†ç±»åˆ—çš„é¢‘æ¬¡åˆ†æ  
   - ç›¸å…³æ€§åˆ†æï¼ˆå¦‚æœé€‚ç”¨ï¼‰
   - å…³é”®å‘ç°å’Œæ´å¯Ÿæ€»ç»“
6. ä¸è¦ä½¿ç”¨plt.show()ï¼Œç›´æ¥ä¿å­˜å›¾è¡¨åˆ°PDF
7. ç¡®ä¿ä»£ç å®Œæ•´å¯è¿è¡Œï¼ŒåŒ…å«æ‰€æœ‰å¿…è¦çš„importè¯­å¥
8. **é‡è¦ï¼šå¤„ç†ä¸­æ–‡æ ‡ç­¾æ—¶ä½¿ç”¨æä¾›çš„è½¬æ¢å‡½æ•°**ï¼š
   ```python
   # å¦‚æœæ‚¨çš„æ•°æ®åŒ…å«ä¸­æ–‡åˆ†ç±»æ ‡ç­¾ï¼Œä½¿ç”¨ä»¥ä¸‹å‡½æ•°è½¬æ¢ä¸ºè‹±æ–‡
   # x_labels = safe_translate_labels(original_labels)
   # ax.set_xticklabels(x_labels)
   
   # æˆ–è€…åœ¨åˆ›å»ºå›¾è¡¨æ—¶ç›´æ¥è½¬æ¢
   # categories = [translate_chinese_to_english(cat) for cat in original_categories]
   ```
9. **å¿…é¡»åŒ…å«matplotlibè‹±æ–‡é…ç½®**ï¼š
   ```python
   import matplotlib.pyplot as plt
   import matplotlib
   matplotlib.rcParams['font.sans-serif'] = ['DejaVu Sans', 'Arial', 'Helvetica']
   matplotlib.rcParams['axes.unicode_minus'] = False
   ```
10. **å¿…é¡»åŒ…å«reportlabä¸­æ–‡å­—ä½“é…ç½®**ï¼š
    ```python
    from reportlab.pdfbase import pdfmetrics
    from reportlab.pdfbase.ttfonts import TTFont
    import os
    
    # æ³¨å†Œä¸­æ–‡å­—ä½“ç”¨äºPDFæ–‡å­—æè¿°
    font_name = 'Helvetica'
    try:
        font_paths_to_try = [
            '/usr/share/fonts/truetype/wqy/wqy-zenhei.ttc',
            '/usr/share/fonts/truetype/wqy/wqy-microhei.ttc',
            '/usr/share/fonts/truetype/dejavu/DejaVuSans.ttf'
        ]
        
        for font_path in font_paths_to_try:
            try:
                if os.path.exists(font_path):
                    if font_path.endswith('.ttc'):
                        pdfmetrics.registerFont(TTFont('ChineseFont', font_path))
                    else:
                        pdfmetrics.registerFont(TTFont('ChineseFont', font_path))
                    font_name = 'ChineseFont'
                    break
            except Exception:
                continue
    except Exception:
        pass  # ä½¿ç”¨é»˜è®¤å­—ä½“
    ```
11. åœ¨åˆ›å»ºPDFæ ·å¼æ—¶ï¼Œä½¿ç”¨ fontName=font_name å‚æ•°
12. ç¡®ä¿æ‰€æœ‰å›¾è¡¨åœ¨ä¿å­˜å‰è°ƒç”¨ plt.savefig()ï¼Œä¿å­˜åè°ƒç”¨ plt.close()

**æ•°æ®ç‰¹ç‚¹è¯´æ˜ï¼š**
- æ•°æ®å¯èƒ½åŒ…å«ä¸­æ–‡åˆ—åå’Œæ–‡æœ¬æ•°æ®
- åŒ…å«æ—¥æœŸæ—¶é—´åˆ—ï¼ˆregister_date, create_time, update_timeï¼‰
- æ•°å€¼åˆ—å¯èƒ½åŒ…æ‹¬total_assets
- éœ€è¦é€‚å½“å¤„ç†éæ•°å€¼åˆ—ï¼Œé¿å…åœ¨æ•°å€¼åˆ†æä¸­å‡ºé”™

**è¾“å‡ºæ ¼å¼è¦æ±‚ï¼š**
- PDFæŠ¥å‘Šåº”è¯¥åŒ…å«ä¸­æ–‡æ–‡å­—æè¿°æ®µè½å’Œå¯¹åº”çš„è‹±æ–‡å›¾è¡¨
- æ¯ä¸ªåˆ†æéƒ¨åˆ†éƒ½åº”è¯¥æœ‰æ¸…æ™°çš„ä¸­æ–‡æ ‡é¢˜å’Œè¯¦ç»†çš„æ–‡å­—è§£é‡Š
- æ–‡å­—æè¿°åº”è¯¥ä¸“ä¸šã€å‡†ç¡®ã€æ˜“äºç†è§£
- **å›¾è¡¨ä¸­çš„æ‰€æœ‰æ–‡å­—ï¼ˆåŒ…æ‹¬åæ ‡è½´æ ‡ç­¾ã€å›¾ä¾‹ã€æ ‡é¢˜ï¼‰å¿…é¡»æ˜¯è‹±æ–‡**

è¯·åªè¿”å›Pythonä»£ç ï¼Œä¸è¦åŒ…å«ä»»ä½•è§£é‡Šæ€§æ–‡å­—ã€‚
"""
                            
                            # è°ƒç”¨å¤§æ¨¡å‹ç”Ÿæˆåˆ†æä»£ç 
                            analysis_code_response = agent.llm.invoke([HumanMessage(content=analysis_prompt)])
                            analysis_code = analysis_code_response.content.strip()
                            
                            # å¦‚æœä»£ç è¢«åŒ…è£¹åœ¨ä»£ç å—ä¸­ï¼Œæå–çº¯ä»£ç 
                            if analysis_code.startswith("```python"):
                                analysis_code = analysis_code[9:-3] if analysis_code.endswith("```") else analysis_code[9:]
                            elif analysis_code.startswith("```"):
                                analysis_code = analysis_code[3:-3] if analysis_code.endswith("```") else analysis_code[3:]
                            
                            # åœ¨æ²™ç®±ä¸­æ‰§è¡Œä»£ç 
                            result = asyncio.run(
                                execute_analysis_code(analysis_code, excel_path, report_path, timeout=120)
                            )
                            
                            if result["success"] and os.path.exists(report_path):
                                # è¯»å–PDFæ–‡ä»¶
                                with open(report_path, "rb") as f:
                                    pdf_bytes = f.read()
                                    
                                # ä¿å­˜åˆ°session stateä»¥ä¾¿ä¸‹è½½
                                report_cache_key = stable_key_for_sql(st.session_state.db_name, message['last_sql'])
                                st.session_state.analysis_reports[report_cache_key] = {
                                    'pdf_bytes': pdf_bytes,
                                    'filename': report_filename
                                }
                                
                                st.success("âœ… æ•°æ®åˆ†ææŠ¥å‘Šç”ŸæˆæˆåŠŸï¼")
                                st.download_button(
                                    label="ğŸ“¥ ä¸‹è½½æ•°æ®åˆ†ææŠ¥å‘Š (PDF)",
                                    data=pdf_bytes,
                                    file_name=report_filename,
                                    mime="application/pdf",
                                    key=f"download-report-{dl_key}"
                                )
                            else:
                                error_msg = result.get("error", "æœªçŸ¥é”™è¯¯")
                                st.error(f"âŒ æŠ¥å‘Šç”Ÿæˆå¤±è´¥: {error_msg}")
                                # æ˜¾ç¤ºç”Ÿæˆçš„ä»£ç ä»¥ä¾¿è°ƒè¯•
                                with st.expander("æŸ¥çœ‹ç”Ÿæˆçš„ä»£ç ï¼ˆç”¨äºè°ƒè¯•ï¼‰"):
                                    st.code(analysis_code, language="python")
                    
                    except Exception as e:
                        st.error(f"âŒ æŠ¥å‘Šç”Ÿæˆå‡ºé”™: {str(e)}")
                        import traceback
                        st.text(traceback.format_exc())
                    finally:
                        # æ¸…ç†ä¸´æ—¶æ–‡ä»¶
                        try:
                            if 'excel_path' in locals() and os.path.exists(excel_path):
                                os.remove(excel_path)
                            if 'report_path' in locals() and os.path.exists(report_path):
                                os.remove(report_path)
                        except Exception:
                            pass

                # å›¾è¡¨æ¸²æŸ“ï¼šä¼˜å…ˆä½¿ç”¨å·²ç¼“å­˜çš„ echarts_optionï¼Œé¿å…é‡å¤è°ƒç”¨ LLM
                if HAS_ECHARTS:
                    cached_viz = message.get("echarts_viz")
                    if cached_viz is not None:
                        # ç›´æ¥ä½¿ç”¨å·²å­˜å‚¨çš„é…ç½®
                        if cached_viz.get("show") and isinstance(cached_viz.get("option"), dict):
                            st.markdown("**ğŸ“Š å¯è§†åŒ–ï¼ˆEChartsï¼‰**")
                            st_echarts(cached_viz["option"], height="420px", key=f"chart-{dl_key}")
                        elif cached_viz.get("reason"):
                            st.caption(f"ğŸ“Š ä¸å±•ç¤ºå›¾è¡¨ï¼š{cached_viz.get('reason', 'æ•°æ®ä¸é€‚åˆ')}")
                    else:
                        # å…œåº•ï¼šä½¿ç”¨ç¼“å­˜å‡½æ•°ï¼ˆä»ç„¶å¯èƒ½è°ƒç”¨ LLMï¼Œä½†æœ‰ TTL ç¼“å­˜ï¼‰
                        try:
                            df_info = build_df_info_for_viz(df_preview, max_rows=20)
                            cache_key = f"hist-{dl_key}"
                            viz = get_cached_echarts_option(
                                cache_key=cache_key,
                                question="(å†å²æ¶ˆæ¯é‡ç»˜)",
                                sql=message.get("last_sql", ""),
                                df_info_json=json.dumps(df_info, ensure_ascii=False, default=str),
                                _agent=agent,
                            )
                            if viz.get("show") and isinstance(viz.get("option"), dict):
                                st.markdown("**ğŸ“Š å¯è§†åŒ–ï¼ˆEChartsï¼‰**")
                                st_echarts(viz["option"], height="420px", key=f"chart-{dl_key}")
                            else:
                                st.caption(f"ğŸ“Š ä¸å±•ç¤ºå›¾è¡¨ï¼š{viz.get('reason', 'æ•°æ®ä¸é€‚åˆ')}")
                        except Exception as e:
                            st.caption(f"ğŸ“Š å›¾è¡¨ç”Ÿæˆå¤±è´¥ï¼š{e}")
            except Exception as e:
                st.caption(f"âš ï¸ æŸ¥è¯¢ç»“æœå±•ç¤ºå¤±è´¥ï¼š{e}")
        
        # æ˜¾ç¤ºæ¶ˆæ¯å†…å®¹ï¼ˆå…è®¸åŠ©æ‰‹æ¶ˆæ¯ content ä¸ºç©ºï¼šåªå±•ç¤ºè¡¨æ ¼/ä¸‹è½½ç­‰ç»„ä»¶ï¼Œä¸é¢å¤–è¾“å‡º"æŸ¥è¯¢å®Œæˆâ€¦"æ–‡æ¡ˆï¼‰
        content = message.get("content", "")
        if isinstance(content, str) and content.strip():
            st.markdown(content)

# è¾“å…¥æ¡†
# è¾“å…¥æ¡†ï¼ˆè¿è¡Œä¸­ç¦ç”¨ï¼Œå¹¶æç¤ºâ€œæ­£åœ¨è¿è¡Œâ€ï¼‰
prompt_input = st.chat_input(
    "è¯·è¾“å…¥æ‚¨çš„é—®é¢˜..." if not st.session_state.is_running else "æ­£åœ¨æŸ¥è¯¢ä¸­ï¼Œè¯·ç¨å€™â€¦",
    disabled=bool(st.session_state.is_running),
)

# ç¬¬ä¸€æ­¥ï¼šç”¨æˆ·æäº¤åå…ˆç¼“å­˜ prompt å¹¶ rerunï¼Œä½¿è¾“å…¥æ¡†ç«‹å³è¿›å…¥â€œè¿è¡Œä¸­â€çŠ¶æ€ï¼ˆæ›´é¡ºæ»‘ï¼‰
if prompt_input:
    st.session_state.pending_prompt = prompt_input
    st.session_state.is_running = True
    st.rerun()

# ç¬¬äºŒæ­¥ï¼šå¦‚æœæœ‰å¾…å¤„ç† prompt ä¸” is_running=Trueï¼Œå°±æ‰§è¡ŒæŸ¥è¯¢
if st.session_state.pending_prompt and st.session_state.is_running:
    prompt = st.session_state.pending_prompt

    # æ·»åŠ ç”¨æˆ·æ¶ˆæ¯ï¼ˆåªæ·»åŠ ä¸€æ¬¡ï¼‰
    st.session_state.messages.append({"role": "user", "content": prompt})
    with st.chat_message("user"):
        st.markdown(prompt)

    with st.chat_message("assistant"):
        # å·¥å…·è°ƒç”¨æµç¨‹å±•ç¤ºï¼ˆé»˜è®¤æŠ˜å ï¼Œç”¨æˆ·ç‚¹å‡»å¯å±•å¼€æŸ¥çœ‹è¯¦æƒ…ï¼‰
        status_box = st.status("æ­£åœ¨æ‰§è¡ŒæŸ¥è¯¢...", expanded=False, state="running")
        live_handler = StreamlitStatusTraceHandler(status_box)

        tool_result = agent.run_tools(prompt, callbacks=[live_handler])

        if tool_result.get("success"):
            status_box.update(label="æŸ¥è¯¢æ‰§è¡ŒæˆåŠŸï¼ˆç‚¹å‡»å±•å¼€è¯¦æƒ…ï¼‰", state="complete", expanded=False)
        else:
            status_box.update(label="æŸ¥è¯¢æ‰§è¡Œå¤±è´¥ï¼ˆç‚¹å‡»æŸ¥çœ‹è¯¦æƒ…ï¼‰", state="error", expanded=False)

        df = None
        full_count = None
        echarts_viz = None  # ç”¨äºç¼“å­˜åˆ°æ¶ˆæ¯

        if tool_result.get("success"):
            if tool_result.get("sql"):
                with st.expander("ğŸ“ æŸ¥çœ‹ç”Ÿæˆçš„ SQL è¯­å¥", expanded=False):
                    st.code(tool_result["sql"], language="sql")

            last_sql = tool_result.get("last_sql", "") or ""
            if last_sql:
                try:
                    # effective_limit æ˜¯ç”¨æˆ·æ„å›¾çš„æ•°é‡
                    # - å…·ä½“æ•°å­—ï¼ˆå¦‚400ï¼‰ï¼šç”¨æˆ·è¯´"å‰400ä¸ª"
                    # - LIMIT_ALL (999999)ï¼šç”¨æˆ·æƒ³è¦å…¨éƒ¨æ•°æ®ï¼ˆå¦‚"æ‰€æœ‰"ã€"åˆ—å‡ºxxx"ï¼‰
                    eff = int(tool_result.get("effective_limit") or 20)
                    eff = max(1, eff)
                    
                    engine = get_sqlalchemy_engine(st.session_state.db_name)
                    
                    # è®¡ç®—"å…¨é‡è¡Œæ•°"ï¼šå¯¹å»æ‰ LIMIT çš„ SQL åš COUNT(*)
                    try:
                        sql_no_limit = strip_trailing_limit(last_sql)
                        count_sql = f"SELECT COUNT(*) FROM ({sql_no_limit}) AS t"
                        full_count = int(execute_scalar(count_sql, engine))
                    except Exception:
                        full_count = None
                    
                    # å¦‚æœç”¨æˆ·æƒ³è¦å…¨éƒ¨æ•°æ®ï¼ˆeff >= LIMIT_ALLï¼‰ï¼Œä¸‹è½½æ•°é‡ä½¿ç”¨ full_count
                    if eff >= LIMIT_ALL and full_count is not None:
                        download_limit = full_count
                    else:
                        download_limit = eff
                    
                    # é¢„è§ˆç”¨ SQLï¼ˆæœ€å¤š20è¡Œï¼‰
                    preview_limit = min(download_limit, 20)
                    preview_sql = sanitize_sql_query(last_sql, default_limit=preview_limit, hard_limit=20)
                    df_preview = execute_sql_to_df(preview_sql, engine)

                    # æ˜¾ç¤ºé¢„è§ˆè¡¨æ ¼
                    if full_count is not None and full_count <= preview_limit:
                        st.markdown(f"**ğŸ“„ æŸ¥è¯¢ç»“æœï¼ˆå…± {full_count} è¡Œï¼Œå·²å…¨éƒ¨å±•ç¤ºï¼‰**")
                    elif full_count is not None:
                        st.markdown(f"**ğŸ“„ æŸ¥è¯¢ç»“æœï¼ˆå‰ {len(df_preview)} è¡Œ / å…± {full_count} è¡Œï¼‰**")
                    else:
                        st.markdown(f"**ğŸ“„ æŸ¥è¯¢ç»“æœï¼ˆå‰ {len(df_preview)} è¡Œï¼‰**")
                    st.dataframe(df_preview, use_container_width=True)

                    # ä¸‹è½½ï¼šä½¿ç”¨ç”¨æˆ·æ„å›¾çš„æ•°é‡ï¼ˆæˆ–å…¨é‡ï¼‰
                    download_sql = sanitize_sql_query(last_sql, default_limit=download_limit, hard_limit=download_limit)
                    df_download = execute_sql_to_df(download_sql, engine)
                    excel_bytes = build_excel_bytes(df_download)
                    filename = f"query_result_{datetime.now().strftime('%Y%m%d_%H%M%S')}.xlsx"
                    download_rows = len(df_download)
                    st.download_button(
                        label=f"â¬‡ï¸ ä¸‹è½½ç»“æœï¼ˆExcelï¼Œå…± {download_rows} è¡Œï¼‰",
                        data=excel_bytes,
                        file_name=filename,
                        mime="application/vnd.openxmlformats-officedocument.spreadsheetml.sheet",
                        key=f"download-live-{stable_key_for_sql(st.session_state.db_name, download_sql)}",
                    )

                    # æ–°å¢ï¼šè‡ªå®šä¹‰åˆ†æè¦æ±‚è¾“å…¥æ¡†ï¼ˆå®æ—¶æŸ¥è¯¢ç»“æœï¼‰
                    custom_analysis_req_live = st.text_input(
                        "ğŸ“Š è‡ªå®šä¹‰åˆ†æè¦æ±‚ï¼ˆå¯é€‰ï¼‰:",
                        key=f"custom-analysis-req-live-{stable_key_for_sql(st.session_state.db_name, download_sql)}",
                        placeholder="ä¾‹å¦‚ï¼šé‡ç‚¹å…³æ³¨é”€å”®é¢è¶‹åŠ¿ã€æŒ‰åœ°åŒºåˆ†ç»„ç»Ÿè®¡ã€ç”Ÿæˆç›¸å…³æ€§çƒ­åŠ›å›¾ç­‰"
                    )

                    # æ–°å¢ï¼šç”Ÿæˆæ•°æ®åˆ†ææŠ¥å‘ŠæŒ‰é’®ï¼ˆå®æ—¶æŸ¥è¯¢ç»“æœï¼‰
                    live_report_key = f"live-report-{stable_key_for_sql(st.session_state.db_name, download_sql)}"
                    if st.button("ğŸ“Š ç”Ÿæˆæ•°æ®åˆ†ææŠ¥å‘Š", key=f"generate-live-report-{stable_key_for_sql(st.session_state.db_name, download_sql)}"):
                        try:
                            with st.spinner("æ­£åœ¨ç”Ÿæˆæ•°æ®åˆ†ææŠ¥å‘Š..."):
                                # ä¿å­˜å½“å‰åˆ†ææ‰€éœ€çš„æ•°æ®
                                st.session_state.current_analysis_df = df_download.copy()
                                st.session_state.current_analysis_question = prompt
                                
                                # ç”ŸæˆExcelæ–‡ä»¶ç”¨äºæ²™ç®±æ‰§è¡Œ
                                excel_filename = f"temp_data_{datetime.now().strftime('%Y%m%d_%H%M%S')}.xlsx"
                                excel_path = f"/tmp/{excel_filename}"
                                df_download.to_excel(excel_path, index=False)
                                
                                # ç”ŸæˆPDFæŠ¥å‘Šæ–‡ä»¶è·¯å¾„
                                report_filename = f"analysis_report_{datetime.now().strftime('%Y%m%d_%H%M%S')}.pdf"
                                report_path = f"/tmp/{report_filename}"
                                
                                # æ„å»ºåˆ†ææç¤ºè¯
                                base_prompt = f"""
ä½ æ˜¯ä¸€åä¸“ä¸šçš„æ•°æ®ç§‘å­¦å®¶ã€‚è¯·åŸºäºç”¨æˆ·çš„é—®é¢˜å’Œæä¾›çš„DataFrameï¼ˆå˜é‡å: dfï¼‰ç”Ÿæˆå®Œæ•´çš„Pythonæ•°æ®åˆ†æä»£ç ã€‚

ç”¨æˆ·é—®é¢˜: {prompt}
"""
                                
                                if custom_analysis_req_live.strip():
                                    base_prompt += f"\nç”¨æˆ·è‡ªå®šä¹‰åˆ†æè¦æ±‚: {custom_analysis_req_live.strip()}\n"
                                
                                analysis_prompt = base_prompt + f"""
è¦æ±‚ï¼š
1. è¿›è¡Œå…¨é¢çš„æ•°æ®åˆ†æï¼ŒåŒ…æ‹¬åŸºæœ¬ç»Ÿè®¡ã€ç›¸å…³æ€§åˆ†æã€åˆ†å¸ƒåˆ†æç­‰
2. ç”Ÿæˆé«˜è´¨é‡çš„å¯è§†åŒ–å›¾è¡¨ï¼ˆä½¿ç”¨matplotlib/seabornï¼‰ï¼Œ**æ‰€æœ‰å›¾è¡¨æ ‡é¢˜ã€æ ‡ç­¾ã€å›¾ä¾‹å¿…é¡»ä½¿ç”¨è‹±æ–‡**
3. å°†æ‰€æœ‰åˆ†æç»“æœæ•´åˆåˆ°ä¸€ä¸ªPDFæŠ¥å‘Šä¸­ï¼Œ**åŒ…å«è¯¦ç»†çš„ä¸­æ–‡æ–‡å­—æè¿°å’Œè§£é‡Š**
4. PDFæŠ¥å‘Šå¿…é¡»ä¿å­˜åˆ°è·¯å¾„: {report_path}
5. **ä¸­æ–‡æ–‡å­—æè¿°å†…å®¹åº”åŒ…æ‹¬**ï¼š
   - æ•°æ®æ¦‚è§ˆï¼ˆå½¢çŠ¶ã€åˆ—ä¿¡æ¯ã€æ•°æ®ç±»å‹ï¼‰
   - ç¼ºå¤±å€¼åˆ†æ
   - åŸºæœ¬ç»Ÿè®¡æ‘˜è¦
   - æ•°å€¼åˆ—çš„åˆ†å¸ƒç‰¹å¾åˆ†æ
   - åˆ†ç±»åˆ—çš„é¢‘æ¬¡åˆ†æ  
   - ç›¸å…³æ€§åˆ†æï¼ˆå¦‚æœé€‚ç”¨ï¼‰
   - å…³é”®å‘ç°å’Œæ´å¯Ÿæ€»ç»“
6. ä¸è¦ä½¿ç”¨plt.show()ï¼Œç›´æ¥ä¿å­˜å›¾è¡¨åˆ°PDF
7. ç¡®ä¿ä»£ç å®Œæ•´å¯è¿è¡Œï¼ŒåŒ…å«æ‰€æœ‰å¿…è¦çš„importè¯­å¥
8. **é‡è¦ï¼šå¤„ç†ä¸­æ–‡æ ‡ç­¾æ—¶ä½¿ç”¨æä¾›çš„è½¬æ¢å‡½æ•°**ï¼š
   ```python
   # å¦‚æœæ‚¨çš„æ•°æ®åŒ…å«ä¸­æ–‡åˆ†ç±»æ ‡ç­¾ï¼Œä½¿ç”¨ä»¥ä¸‹å‡½æ•°è½¬æ¢ä¸ºè‹±æ–‡
   # x_labels = safe_translate_labels(original_labels)
   # ax.set_xticklabels(x_labels)
   
   # æˆ–è€…åœ¨åˆ›å»ºå›¾è¡¨æ—¶ç›´æ¥è½¬æ¢
   # categories = [translate_chinese_to_english(cat) for cat in original_categories]
   ```
9. **å¿…é¡»åŒ…å«matplotlibè‹±æ–‡é…ç½®**ï¼š
   ```python
   import matplotlib.pyplot as plt
   import matplotlib
   matplotlib.rcParams['font.sans-serif'] = ['DejaVu Sans', 'Arial', 'Helvetica']
   matplotlib.rcParams['axes.unicode_minus'] = False
   ```
10. **å¿…é¡»åŒ…å«reportlabä¸­æ–‡å­—ä½“é…ç½®**ï¼š
    ```python
    from reportlab.pdfbase import pdfmetrics
    from reportlab.pdfbase.ttfonts import TTFont
    import os
    
    # æ³¨å†Œä¸­æ–‡å­—ä½“ç”¨äºPDFæ–‡å­—æè¿°
    font_name = 'Helvetica'
    try:
        font_paths_to_try = [
            '/usr/share/fonts/truetype/wqy/wqy-zenhei.ttc',
            '/usr/share/fonts/truetype/wqy/wqy-microhei.ttc',
            '/usr/share/fonts/truetype/dejavu/DejaVuSans.ttf'
        ]
        
        for font_path in font_paths_to_try:
            try:
                if os.path.exists(font_path):
                    if font_path.endswith('.ttc'):
                        pdfmetrics.registerFont(TTFont('ChineseFont', font_path))
                    else:
                        pdfmetrics.registerFont(TTFont('ChineseFont', font_path))
                    font_name = 'ChineseFont'
                    break
            except Exception:
                continue
    except Exception:
        pass  # ä½¿ç”¨é»˜è®¤å­—ä½“
    ```
11. åœ¨åˆ›å»ºPDFæ ·å¼æ—¶ï¼Œä½¿ç”¨ fontName=font_name å‚æ•°
12. ç¡®ä¿æ‰€æœ‰å›¾è¡¨åœ¨ä¿å­˜å‰è°ƒç”¨ plt.savefig()ï¼Œä¿å­˜åè°ƒç”¨ plt.close()

**æ•°æ®ç‰¹ç‚¹è¯´æ˜ï¼š**
- æ•°æ®å¯èƒ½åŒ…å«ä¸­æ–‡åˆ—åå’Œæ–‡æœ¬æ•°æ®
- åŒ…å«æ—¥æœŸæ—¶é—´åˆ—ï¼ˆregister_date, create_time, update_timeï¼‰
- æ•°å€¼åˆ—å¯èƒ½åŒ…æ‹¬total_assets
- éœ€è¦é€‚å½“å¤„ç†éæ•°å€¼åˆ—ï¼Œé¿å…åœ¨æ•°å€¼åˆ†æä¸­å‡ºé”™

**è¾“å‡ºæ ¼å¼è¦æ±‚ï¼š**
- PDFæŠ¥å‘Šåº”è¯¥åŒ…å«ä¸­æ–‡æ–‡å­—æè¿°æ®µè½å’Œå¯¹åº”çš„è‹±æ–‡å›¾è¡¨
- æ¯ä¸ªåˆ†æéƒ¨åˆ†éƒ½åº”è¯¥æœ‰æ¸…æ™°çš„ä¸­æ–‡æ ‡é¢˜å’Œè¯¦ç»†çš„æ–‡å­—è§£é‡Š
- æ–‡å­—æè¿°åº”è¯¥ä¸“ä¸šã€å‡†ç¡®ã€æ˜“äºç†è§£
- **å›¾è¡¨ä¸­çš„æ‰€æœ‰æ–‡å­—ï¼ˆåŒ…æ‹¬åæ ‡è½´æ ‡ç­¾ã€å›¾ä¾‹ã€æ ‡é¢˜ï¼‰å¿…é¡»æ˜¯è‹±æ–‡**

è¯·åªè¿”å›Pythonä»£ç ï¼Œä¸è¦åŒ…å«ä»»ä½•è§£é‡Šæ€§æ–‡å­—ã€‚
"""
                                
                                # è°ƒç”¨å¤§æ¨¡å‹ç”Ÿæˆåˆ†æä»£ç 
                                analysis_code_response = agent.llm.invoke([HumanMessage(content=analysis_prompt)])
                                analysis_code = analysis_code_response.content.strip()
                                
                                # å¦‚æœä»£ç è¢«åŒ…è£¹åœ¨ä»£ç å—ä¸­ï¼Œæå–çº¯ä»£ç 
                                if analysis_code.startswith("```python"):
                                    analysis_code = analysis_code[9:-3] if analysis_code.endswith("```") else analysis_code[9:]
                                elif analysis_code.startswith("```"):
                                    analysis_code = analysis_code[3:-3] if analysis_code.endswith("```") else analysis_code[3:]
                                
                                # åœ¨æ²™ç®±ä¸­æ‰§è¡Œä»£ç 
                                result = asyncio.run(
                                    execute_analysis_code(analysis_code, excel_path, report_path, timeout=120)
                                )
                                
                                if result["success"] and os.path.exists(report_path):
                                    # è¯»å–PDFæ–‡ä»¶
                                    with open(report_path, "rb") as f:
                                        pdf_bytes = f.read()
                                        
                                    # ä¿å­˜åˆ°session stateä»¥ä¾¿ä¸‹è½½
                                    report_cache_key = stable_key_for_sql(st.session_state.db_name, download_sql)
                                    st.session_state.analysis_reports[report_cache_key] = {
                                        'pdf_bytes': pdf_bytes,
                                        'filename': report_filename
                                    }
                                    
                                    st.success("âœ… æ•°æ®åˆ†ææŠ¥å‘Šç”ŸæˆæˆåŠŸï¼")
                                    st.download_button(
                                        label="ğŸ“¥ ä¸‹è½½æ•°æ®åˆ†ææŠ¥å‘Š (PDF)",
                                        data=pdf_bytes,
                                        file_name=report_filename,
                                        mime="application/pdf",
                                        key=f"download-live-report-{stable_key_for_sql(st.session_state.db_name, download_sql)}"
                                    )
                                else:
                                    error_msg = result.get("error", "æœªçŸ¥é”™è¯¯")
                                    st.error(f"âŒ æŠ¥å‘Šç”Ÿæˆå¤±è´¥: {error_msg}")
                                    # æ˜¾ç¤ºç”Ÿæˆçš„ä»£ç ä»¥ä¾¿è°ƒè¯•
                                    with st.expander("æŸ¥çœ‹ç”Ÿæˆçš„ä»£ç ï¼ˆç”¨äºè°ƒè¯•ï¼‰"):
                                        st.code(analysis_code, language="python")
                        
                        except Exception as e:
                            st.error(f"âŒ æŠ¥å‘Šç”Ÿæˆå‡ºé”™: {str(e)}")
                            import traceback
                            st.text(traceback.format_exc())
                        finally:
                            # æ¸…ç†ä¸´æ—¶æ–‡ä»¶
                            try:
                                if 'excel_path' in locals() and os.path.exists(excel_path):
                                    os.remove(excel_path)
                                if 'report_path' in locals() and os.path.exists(report_path):
                                    os.remove(report_path)
                            except Exception:
                                pass

                    # å¯è§†åŒ–ç”Ÿæˆï¼ˆä½¿ç”¨é¢„è§ˆæ•°æ®ï¼‰
                    if HAS_ECHARTS:
                        chart_placeholder = st.empty()
                        chart_placeholder.info("æ­£åœ¨ç”Ÿæˆå¯è§†åŒ–å›¾è¡¨...")
                        
                        try:
                            df_info = build_df_info_for_viz(df_preview, max_rows=20)
                            viz = agent.generate_echarts_option(
                                question=prompt,
                                sql=tool_result.get("sql", ""),
                                df_info=df_info,
                            )
                            echarts_viz = viz  # ç¼“å­˜åˆ°æ¶ˆæ¯
                            
                            chart_placeholder.empty()  # æ¸…é™¤ loading æç¤º
                            if viz.get("show") and isinstance(viz.get("option"), dict):
                                st.markdown("**ğŸ“Š å¯è§†åŒ–ï¼ˆEChartsï¼‰**")
                                st_echarts(viz["option"], height="420px", key=f"chart-live-{stable_key_for_sql(st.session_state.db_name, preview_sql)}")
                            else:
                                st.caption(f"ğŸ“Š ä¸å±•ç¤ºå›¾è¡¨ï¼š{viz.get('reason', 'æ•°æ®ä¸é€‚åˆ')}")
                        except Exception as e:
                            chart_placeholder.empty()
                            st.caption(f"ğŸ“Š å›¾è¡¨ç”Ÿæˆå¤±è´¥ï¼š{e}")
                            echarts_viz = {"show": False, "reason": str(e)}
                    else:
                        st.caption("ğŸ“Š æœªå®‰è£… `streamlit-echarts`ï¼Œæš‚ä¸å±•ç¤ºå›¾è¡¨ã€‚")
                except Exception as e:
                    st.caption(f"âš ï¸ æŸ¥è¯¢ç»“æœå±•ç¤ºå¤±è´¥ï¼š{e}")
            else:
                st.caption("âš ï¸ æœªæ•è·åˆ°å¯ç”¨äºå±•ç¤ºçš„æ•°æ®æŸ¥è¯¢ SQLï¼ˆlast_sql ä¸ºç©ºï¼‰ã€‚")

            # ä¿å­˜åˆ°æ¶ˆæ¯å†å²ï¼šä¿å­˜ last_sql + effective_limit + full_count + echarts_viz
            msg = {"role": "assistant", "content": ""}
            if tool_result.get("sql"):
                msg["sql"] = tool_result["sql"]
            if tool_result.get("last_sql"):
                msg["last_sql"] = tool_result["last_sql"]
            msg["effective_limit"] = int(tool_result.get("effective_limit") or 20)
            if full_count is not None:
                msg["full_count"] = int(full_count)
            if echarts_viz is not None:
                msg["echarts_viz"] = echarts_viz  # ç¼“å­˜å›¾è¡¨é…ç½®ï¼Œå†å²æ¸²æŸ“æ—¶ç›´æ¥ä½¿ç”¨
            st.session_state.messages.append(msg)
        else:
            error_msg = f"âŒ æŸ¥è¯¢å¤±è´¥: {tool_result.get('error', 'æœªçŸ¥é”™è¯¯')}"
            st.error(error_msg)
            st.session_state.messages.append({"role": "assistant", "content": error_msg})

    # æ¸…ç†è¿è¡Œæ ‡è®°å¹¶ rerunï¼Œæ¢å¤è¾“å…¥æ¡†
    st.session_state.pending_prompt = None
    st.session_state.is_running = False
    st.rerun()

# ï¼ˆå·²ç§»é™¤ï¼‰ç¤ºä¾‹é—®é¢˜ã€ç³»ç»Ÿä¿¡æ¯ï¼šä¿æŒèŠå¤©ç•Œé¢ç®€æ´
